{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1de0f1a",
   "metadata": {
    "id": "d1de0f1a"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/docs/examples/ingestion/parallel_execution_ingestion_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cbe152-de29-4240-8e13-f74dc146a658",
   "metadata": {
    "id": "c8cbe152-de29-4240-8e13-f74dc146a658"
   },
   "source": [
    "# Parallelizing llamaindex RAG Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-ElrAEOGDSHt",
   "metadata": {
    "id": "-ElrAEOGDSHt",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 0. Pré-requis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef3ff0cf-4859-4de0-9238-aca8e2903ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install llama-index-cli\n",
    "#%pip install llama-index-embeddings-openai\n",
    "#%pip install llama-index-readers-file\n",
    "#%pip install llama-index-embeddings-huggingface\n",
    "#%pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0963707-6ebe-4441-a363-1bfb48ce9df3",
   "metadata": {
    "id": "e0963707-6ebe-4441-a363-1bfb48ce9df3"
   },
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ebec124-1aaf-4181-a0e0-93c09bb644d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile, pstats\n",
    "from pstats import SortKey\n",
    "import time\n",
    "import asyncio\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2VVToRRpCjTh",
   "metadata": {
    "id": "2VVToRRpCjTh"
   },
   "source": [
    "### Téléchargement des données\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92686bb0-85ed-4bb3-99eb-f5fc6c100787",
   "metadata": {
    "id": "92686bb0-85ed-4bb3-99eb-f5fc6c100787"
   },
   "source": [
    "For this notebook, we'll load the `PatronusAIFinanceBenchDataset` llama-dataset from [llamahub](https://llamahub.ai)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3b94d62-efa4-479a-9215-e094b5a73061",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a3b94d62-efa4-479a-9215-e094b5a73061",
    "outputId": "12cbd8a7-dfce-4155-cf1b-4c57c56c4637"
   },
   "outputs": [],
   "source": [
    "# !llamaindex-cli download-llamadataset PatronusAIFinanceBenchDataset --download-dir ./data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d58be293-ced5-4cf4-90e4-11b1c0af5620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rag_dataset.json  source_files\ttest_sample\n"
     ]
    }
   ],
   "source": [
    "!ls ./data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fba575e-2635-4598-a74a-d4036c1816db",
   "metadata": {
    "id": "2fba575e-2635-4598-a74a-d4036c1816db",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 1. Pipeline chargement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iCaePX5DCyJ7",
   "metadata": {
    "id": "iCaePX5DCyJ7"
   },
   "source": [
    "**Il y a 32 pdfs d'une centaine de pages dans les données PatronusAIFinanceBenchDataset .**\n",
    "\n",
    "Définition du Reader :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9K7iToMEbdc",
   "metadata": {
    "id": "f9K7iToMEbdc"
   },
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "# define our reader with the directory containing the 32 pdf files\n",
    "\n",
    "input_dir = \"./data/source_files\"  # \"./data/source_files\"\n",
    "\n",
    "reader = SimpleDirectoryReader(\n",
    "    input_dir=input_dir,  \n",
    "    #required_exts=[\".pdf\"],\n",
    "    recursive=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AwbS0ztWEorx",
   "metadata": {
    "id": "AwbS0ztWEorx"
   },
   "source": [
    "### 1.1 Chargement séquentiel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f49f7e5b-6430-426b-b239-e9280ea7b229",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f49f7e5b-6430-426b-b239-e9280ea7b229",
    "outputId": "982ad887-3e78-4fd9-f8b5-686221db1052"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading files:  94%|█████████████████████████████████████████████▉   | 30/32 [14:46<00:25, 12.77s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7f514d445d30 state=finished raised DependencyError>]. Skipping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading files: 100%|█████████████████████████████████████████████████| 32/32 [15:10<00:00, 28.45s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Création de 4207 documents en 910.300127029419s.\n",
      "Sun Feb  9 20:13:42 2025    ./profiling/stats_sequential_load\n",
      "\n",
      "         1820747227 function calls (1817825827 primitive calls) in 910.301 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 1353 to 15 due to restriction <15>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "   130/95    0.199    0.002  956.069   10.064 threading.py:637(wait)\n",
      "   130/95    0.660    0.005  941.228    9.908 threading.py:323(wait)\n",
      "       32    0.001    0.000  910.283   28.446 base.py:493(load_file)\n",
      "       32    0.000    0.000  909.020   28.407 __init__.py:328(wrapped_f)\n",
      "     4207    2.803    0.001  851.330    0.202 _page.py:2266(extract_text)\n",
      "4345/4207   14.098    0.003  836.333    0.199 _page.py:1822(_extract_text)\n",
      "       32    0.000    0.000  801.757   25.055 __init__.py:465(__call__)\n",
      "       34    0.068    0.002  789.449   23.219 base.py:36(load_data)\n",
      "     4345    0.017    0.000  594.638    0.137 _data_structures.py:1418(operations)\n",
      "     4345   84.655    0.019  580.954    0.134 _data_structures.py:1294(_parse_content_stream)\n",
      "35812602/33327563   68.692    0.000  382.169    0.000 _data_structures.py:1446(read_object)\n",
      " 23032437   36.794    0.000  204.462    0.000 _page.py:1908(process_operation)\n",
      " 47858941  106.713    0.000  164.297    0.000 _utils.py:218(read_until_regex)\n",
      " 24915949   25.385    0.000  137.058    0.000 _base.py:566(read_from_stream)\n",
      "      357    0.145    0.000  103.745    0.291 nest_asyncio.py:100(_run_once)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x7f515756ccb0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profiler = cProfile.Profile()\n",
    "\n",
    "tic = time.time()\n",
    "profiler.enable()\n",
    "documents = reader.load_data(show_progress=True)\n",
    "profiler.disable()\n",
    "print(f\"\\nCréation de {len(documents)} documents en {time.time()-tic}s.\")\n",
    "\n",
    "profiler.dump_stats('./profiling/stats_sequential_load')\n",
    "p = pstats.Stats(\"./profiling/stats_sequential_load\")\n",
    "p.strip_dirs().sort_stats(SortKey.CUMULATIVE).print_stats(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "K-CJ5cr6hdPM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K-CJ5cr6hdPM",
    "outputId": "18fd25f7-4fe9-40b9-c694-b0241db9e724"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps d'exécution moyen du loader sur 7 ittérations :\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7f5141976e10 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7f514236b110 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7f5143a735c0 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7f514363f530 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7f5145e6f3e0 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7f514583b650 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7f5141cd7770 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7f51429e38f0 state=finished raised DependencyError>]. Skipping...\n",
      "3min 43s ± 11 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Temps d'exécution moyen du loader sur 7 ittérations :\")\n",
    "%timeit reader.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "n4hRYI8RIYwB",
   "metadata": {
    "id": "n4hRYI8RIYwB"
   },
   "source": [
    "### 1.2 Chargement parallèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "vjYOfR3_RDB7",
   "metadata": {
    "id": "vjYOfR3_RDB7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPUs: 8\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "num_cpus = multiprocessing.cpu_count()\n",
    "print(f\"Number of CPUs: {num_cpus}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3869775f-652a-45f5-8c27-8884399c5e2a",
   "metadata": {},
   "source": [
    "#### a) Num_workers=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "BnEtFe4AIibM",
   "metadata": {
    "id": "BnEtFe4AIibM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7efcb0eca1e0 state=finished raised DependencyError>]. Skipping...\n",
      "\n",
      "Création de 4207 documents en 111.52120780944824s.\n",
      "Sun Feb  9 20:45:18 2025    ./profiling/stats_parallel_load_worker4\n",
      "\n",
      "         108709 function calls (108330 primitive calls) in 111.754 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 587 to 15 due to restriction <15>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "      375    0.003    0.000  167.432    0.446 pool.py:333(_maintain_pool)\n",
      "      3/2    0.000    0.000  111.518   55.759 interactiveshell.py:3543(run_code)\n",
      "      7/2    0.003    0.000  111.518   55.759 {built-in method builtins.exec}\n",
      "      2/1    0.197    0.099  111.152  111.152 1138091397.py:1(<module>)\n",
      "        1    0.000    0.000  110.891  110.891 base.py:664(load_data)\n",
      "       11    0.000    0.000  110.886   10.081 util.py:208(__call__)\n",
      "        1    0.000    0.000  110.886  110.886 pool.py:738(__exit__)\n",
      "        1    0.000    0.000  110.886  110.886 pool.py:654(terminate)\n",
      "        1    0.000    0.000  110.886  110.886 pool.py:680(_terminate_pool)\n",
      "       20    0.000    0.000  110.575    5.529 connection.py:202(send)\n",
      "        1    0.000    0.000  110.574  110.574 pool.py:671(_help_stuff_finish)\n",
      "       13    0.000    0.000  110.574    8.506 {method 'acquire' of '_multiprocessing.SemLock' objects}\n",
      "      3/1    0.000    0.000  110.574  110.574 threading.py:1016(_bootstrap)\n",
      "      3/1    0.000    0.000  110.573  110.573 threading.py:1056(_bootstrap_inner)\n",
      "      3/1    0.000    0.000  110.573  110.573 ipkernel.py:744(run_closure)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x7f5144436ea0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profiler = cProfile.Profile()\n",
    "\n",
    "tic = time.time()\n",
    "profiler.enable()\n",
    "documents = reader.load_data(num_workers=4, show_progress=True)\n",
    "profiler.disable()\n",
    "print(f\"\\nCréation de {len(documents)} documents en {time.time()-tic}s.\")\n",
    "\n",
    "profiler.dump_stats('./profiling/stats_parallel_load_worker4')\n",
    "p = pstats.Stats(\"./profiling/stats_parallel_load_worker4\")\n",
    "p.strip_dirs().sort_stats(SortKey.CUMULATIVE).print_stats(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1Zy1FMZUhsxh",
   "metadata": {
    "id": "1Zy1FMZUhsxh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps d'exécution moyen du loader sur 7 ittérations :\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7f2986e0c4a0 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7fbb2945fb60 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7f637d544080 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7fe0d0824560 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7f7a96a7fbf0 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7fd64ea94710 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7f6189e80b30 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7f3a5067f920 state=finished raised DependencyError>]. Skipping...\n",
      "1min 41s ± 611 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Temps d'exécution moyen du loader sur 7 ittérations :\")\n",
    "%timeit reader.load_data(num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910b0423-60a1-47f1-9d46-091122fea0db",
   "metadata": {},
   "source": [
    "#### b) Num_workers=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "065155de-b43a-4d46-b788-7f2c3882f1d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7f8909cb14c0 state=finished raised DependencyError>]. Skipping...\n",
      "\n",
      "Création de 4207 documents en 94.99244618415833s.\n",
      "Sun Feb  9 21:00:22 2025    ./profiling/stats_parallel_load_worker8\n",
      "\n",
      "         333520 function calls (333208 primitive calls) in 95.439 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 464 to 15 due to restriction <15>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "       15    0.000    0.000   94.945    6.330 util.py:208(__call__)\n",
      "        1    0.000    0.000   94.945   94.945 pool.py:654(terminate)\n",
      "        1    0.000    0.000   94.945   94.945 pool.py:680(_terminate_pool)\n",
      "       40    0.000    0.000   94.853    2.371 connection.py:202(send)\n",
      "        1    0.000    0.000   94.852   94.852 pool.py:671(_help_stuff_finish)\n",
      "       10    0.000    0.000   94.852    9.485 {method 'acquire' of '_multiprocessing.SemLock' objects}\n",
      "       78    0.001    0.000   94.852    1.216 {built-in method posix.write}\n",
      "      3/1    0.000    0.000   94.852   94.852 threading.py:1016(_bootstrap)\n",
      "      3/1    0.000    0.000   94.852   94.852 threading.py:1056(_bootstrap_inner)\n",
      "      3/1    0.455    0.152   94.852   94.852 ipkernel.py:744(run_closure)\n",
      "      3/1    0.003    0.001   94.852   94.852 threading.py:999(run)\n",
      "        1    0.000    0.000   94.852   94.852 pool.py:527(_handle_tasks)\n",
      "       45    0.000    0.000   94.852    2.108 connection.py:406(_send_bytes)\n",
      "       45    0.000    0.000   94.851    2.108 connection.py:381(_send)\n",
      "        1    0.000    0.000   94.850   94.850 pool.py:573(_handle_results)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x7f514d455880>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profiler = cProfile.Profile()\n",
    "\n",
    "tic = time.time()\n",
    "profiler.enable()\n",
    "documents = reader.load_data(num_workers=8, show_progress=True)\n",
    "profiler.disable()\n",
    "print(f\"\\nCréation de {len(documents)} documents en {time.time()-tic}s.\")\n",
    "\n",
    "profiler.dump_stats('./profiling/stats_parallel_load_worker8')\n",
    "p = pstats.Stats(\"./profiling/stats_parallel_load_worker8\")\n",
    "p.strip_dirs().sort_stats(SortKey.CUMULATIVE).print_stats(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64afafa6-5170-496e-950d-5ffee5f3623a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps d'exécution moyen du loader sur 7 ittérations :\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7f19013d6db0 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7f2936a6c080 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7f82a86fe6f0 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7fd0b40c09e0 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7ff789b0d5e0 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7f7ca1ad6750 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7fe42ca6bec0 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7f79a646ff20 state=finished raised DependencyError>]. Skipping...\n",
      "1min 37s ± 2.9 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Temps d'exécution moyen du loader sur 7 ittérations :\")\n",
    "%timeit reader.load_data(num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mxFLZcmCLBqI",
   "metadata": {
    "id": "mxFLZcmCLBqI"
   },
   "source": [
    "### 1.3 Chargement asynchrone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8DseaNnbMFsl",
   "metadata": {
    "id": "8DseaNnbMFsl"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                           | 0/32 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7f514d447b90 state=finished raised DependencyError>]. Skipping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 32/32 [13:51<00:00, 25.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Création de 4207 documents en 831.3364579677582s.\n",
      "Sun Feb  9 21:27:10 2025    ./profiling/stats_async_load\n",
      "\n",
      "         1820599888 function calls (1817681631 primitive calls) in 831.374 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 746 to 15 due to restriction <15>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "  191/190    0.204    0.001  868.185    4.569 nest_asyncio.py:100(_run_once)\n",
      "       32    0.000    0.000  831.054   25.970 __init__.py:328(wrapped_f)\n",
      "       32    0.001    0.000  831.053   25.970 __init__.py:465(__call__)\n",
      "   258/83    0.045    0.000  826.017    9.952 events.py:86(_run)\n",
      "     4207    2.685    0.001  819.466    0.195 _page.py:2266(extract_text)\n",
      "4345/4207   13.630    0.003  808.466    0.192 _page.py:1822(_extract_text)\n",
      "       34    0.066    0.002  792.692   23.314 base.py:36(load_data)\n",
      "     4345    0.016    0.000  580.748    0.134 _data_structures.py:1418(operations)\n",
      "     4345   88.023    0.020  568.086    0.131 _data_structures.py:1294(_parse_content_stream)\n",
      "35812602/33327563   64.370    0.000  355.928    0.000 _data_structures.py:1446(read_object)\n",
      " 23032437   35.450    0.000  195.308    0.000 _page.py:1908(process_operation)\n",
      " 47858941  106.560    0.000  160.735    0.000 _utils.py:218(read_until_regex)\n",
      " 24915949   24.484    0.000  130.107    0.000 _base.py:566(read_from_stream)\n",
      "  8641959   41.158    0.000  100.164    0.000 _utils.py:14(read_hex_string_from_stream)\n",
      "  9418815   12.007    0.000   80.955    0.000 _page.py:1786(_handle_tj)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x7f514ea45910>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profiler = cProfile.Profile()\n",
    "\n",
    "tic = time.time()\n",
    "profiler.enable()\n",
    "documents = await reader.aload_data(show_progress=True)\n",
    "profiler.disable()\n",
    "print(f\"\\nCréation de {len(documents)} documents en {time.time()-tic}s.\")\n",
    "\n",
    "profiler.dump_stats('./profiling/stats_async_load')\n",
    "p = pstats.Stats(\"./profiling/stats_async_load\")\n",
    "p.strip_dirs().sort_stats(SortKey.CUMULATIVE).print_stats(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "IU9dh0GSh-2r",
   "metadata": {
    "id": "IU9dh0GSh-2r"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps d'exécution moyen du loader sur 7 ittérations :\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7f51421a36b0 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7f51405ef4a0 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7f5142a22ed0 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7f51431b6d20 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7f5143773770 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7f5146793470 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7f5146662db0 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7f51405469c0 state=finished raised DependencyError>]. Skipping...\n",
      "3min 52s ± 16.2 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "loop = asyncio.get_event_loop()\n",
    "print(f\"Temps d'exécution moyen du loader sur 7 ittérations :\")\n",
    "%timeit loop.run_until_complete(reader.aload_data())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "I_29ZH-mLFJX",
   "metadata": {
    "id": "I_29ZH-mLFJX"
   },
   "source": [
    "### 1.4 Chargement asynchrone et parallèle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f95508-8359-47a1-89ff-0f8604ea77c0",
   "metadata": {},
   "source": [
    "#### a) Num_workers=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "AxlcBM3eSuaw",
   "metadata": {
    "id": "AxlcBM3eSuaw"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                           | 0/32 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7f514d934c20 state=finished raised DependencyError>]. Skipping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 32/32 [15:09<00:00, 28.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Création de 4207 documents en 910.0696785449982s.\n",
      "Sun Feb  9 22:13:07 2025    ./profiling/stats_parallel_async_load_worker4\n",
      "\n",
      "         1820604637 function calls (1817686458 primitive calls) in 910.324 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 700 to 15 due to restriction <15>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "       33    0.000    0.000  910.065   27.578 tasks.py:308(__step_run_and_handle_result)\n",
      "       33    0.000    0.000  910.064   27.578 {method 'send' of 'coroutine' objects}\n",
      "       32    0.112    0.003  909.751   28.430 asyncio.py:75(wrap_awaitable)\n",
      "       34    0.003    0.000  909.648   26.754 dispatcher.py:349(async_wrapper)\n",
      "       32    0.003    0.000  909.626   28.426 async_utils.py:136(worker)\n",
      "       32    0.001    0.000  909.616   28.426 base.py:594(aload_file)\n",
      "       32    0.000    0.000  909.328   28.416 base.py:38(aload_data)\n",
      "       32    0.000    0.000  909.328   28.416 __init__.py:328(wrapped_f)\n",
      "   274/78    0.207    0.001  901.729   11.561 events.py:86(_run)\n",
      "       32    0.001    0.000  873.399   27.294 __init__.py:465(__call__)\n",
      "       34    0.071    0.002  868.438   25.542 base.py:36(load_data)\n",
      "     4207    2.914    0.001  859.440    0.204 _page.py:2266(extract_text)\n",
      "4345/4207   14.170    0.003  849.755    0.202 _page.py:1822(_extract_text)\n",
      "     4345    0.024    0.000  593.657    0.137 _data_structures.py:1418(operations)\n",
      "     4345   87.418    0.020  581.388    0.134 _data_structures.py:1294(_parse_content_stream)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x7f514e938290>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profiler = cProfile.Profile()\n",
    "\n",
    "tic = time.time()\n",
    "profiler.enable()\n",
    "documents = await reader.aload_data(num_workers=4, show_progress=True)\n",
    "profiler.disable()\n",
    "print(f\"\\nCréation de {len(documents)} documents en {time.time()-tic}s.\")\n",
    "\n",
    "profiler.dump_stats('./profiling/stats_parallel_async_load_worker4')\n",
    "p = pstats.Stats(\"./profiling/stats_parallel_async_load_worker4\")\n",
    "p.strip_dirs().sort_stats(SortKey.CUMULATIVE).print_stats(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "qacR4M7Iit9e",
   "metadata": {
    "id": "qacR4M7Iit9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps d'exécution moyen du loader sur 7 ittérations :\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7f5144af8e00 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7f51437ff980 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7f51418dd880 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7f5143d289b0 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7f51420a8590 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7f5143e6e1b0 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7f5147abbfb0 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7f5143387a70 state=finished raised DependencyError>]. Skipping...\n",
      "3min 51s ± 29.8 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "loop = asyncio.get_event_loop()\n",
    "print(f\"Temps d'exécution moyen du loader sur 7 ittérations :\")\n",
    "%timeit loop.run_until_complete(reader.aload_data(num_workers=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dcd6d4-302f-41e3-97d0-0d6a963c039f",
   "metadata": {},
   "source": [
    "#### b) Num_workers=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4033b1c5-8405-4d62-9290-6896976d5ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                           | 0/32 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7f514e980b30 state=finished raised DependencyError>]. Skipping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 32/32 [14:09<00:00, 26.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Création de 4207 documents en 849.7532970905304s.\n",
      "Sun Feb  9 22:58:37 2025    ./profiling/stats_parallel_async_load_worker8\n",
      "\n",
      "         1820603793 function calls (1817684805 primitive calls) in 849.751 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 708 to 15 due to restriction <15>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "       32    0.001    0.000  849.482   26.546 base.py:594(aload_file)\n",
      "       32    0.000    0.000  849.405   26.544 base.py:38(aload_data)\n",
      "       32    0.000    0.000  849.405   26.544 __init__.py:328(wrapped_f)\n",
      "       32    0.001    0.000  848.776   26.524 __init__.py:465(__call__)\n",
      "     4207    2.931    0.001  836.551    0.199 _page.py:2266(extract_text)\n",
      "4345/4207   14.022    0.003  820.634    0.195 _page.py:1822(_extract_text)\n",
      "       34    0.073    0.002  775.702   22.815 base.py:36(load_data)\n",
      "     4345    0.036    0.000  589.351    0.136 _data_structures.py:1418(operations)\n",
      "     4345   84.023    0.019  576.355    0.133 _data_structures.py:1294(_parse_content_stream)\n",
      "35812602/33327563   65.342    0.000  366.191    0.000 _data_structures.py:1446(read_object)\n",
      " 23032437   36.560    0.000  201.679    0.000 _page.py:1908(process_operation)\n",
      " 47858941  114.071    0.000  168.890    0.000 _utils.py:218(read_until_regex)\n",
      " 24915949   25.901    0.000  135.376    0.000 _base.py:566(read_from_stream)\n",
      "  8641959   41.033    0.000  103.193    0.000 _utils.py:14(read_hex_string_from_stream)\n",
      "  9418815   12.395    0.000   83.729    0.000 _page.py:1786(_handle_tj)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x7f51463b7650>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profiler = cProfile.Profile()\n",
    "\n",
    "tic = time.time()\n",
    "profiler.enable()\n",
    "documents = await reader.aload_data(num_workers=8, show_progress=True)\n",
    "profiler.disable()\n",
    "print(f\"\\nCréation de {len(documents)} documents en {time.time()-tic}s.\")\n",
    "\n",
    "profiler.dump_stats('./profiling/stats_parallel_async_load_worker8')\n",
    "p = pstats.Stats(\"./profiling/stats_parallel_async_load_worker8\")\n",
    "p.strip_dirs().sort_stats(SortKey.CUMULATIVE).print_stats(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "319ca151-9732-4645-b9fd-a47bd9b0579d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps d'exécution moyen du loader sur 7 ittérations :\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7f514325e000 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7f51425d6150 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7f51427420c0 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7f5145d51cd0 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7f5147a3d9a0 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7f51428b5a00 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7f5141b2cf80 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7f5143054a40 state=finished raised DependencyError>]. Skipping...\n",
      "3min 34s ± 6.83 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "loop = asyncio.get_event_loop()\n",
    "print(f\"Temps d'exécution moyen du loader sur 7 ittérations :\")\n",
    "%timeit loop.run_until_complete(reader.aload_data(num_workers=8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d691b121-20cb-4257-b9eb-f756c169e63a",
   "metadata": {},
   "source": [
    "### 1.5 Chargement asynchrone avec des fichiers par lots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "560acdb3-48c5-4bd1-880d-19c0ae66a0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def lister_fichiers(dossier):\n",
    "    return [str(fichier) for fichier in Path(dossier).rglob('*') if fichier.is_file()]\n",
    "\n",
    "fichiers = lister_fichiers(input_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4086eee6-c736-4d5c-8de7-0e250bc3fccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_filenames_into_splits(filenames, num_jobs):\n",
    "    tic = time.time()\n",
    "    filenames_splits = [filenames[i::num_jobs] for i in range(num_jobs)]\n",
    "    print(f\"Séparation de {len(filenames)} fichiers en {num_jobs} listes en {round(time.time()-tic, 2)}s de taille {[len(job) for job in filenames_splits]}\")\n",
    "    return filenames_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3af305-9e73-4f95-9ff0-33bf2ff3c640",
   "metadata": {},
   "source": [
    "#### a) 4 splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "127a7beb-e15b-414c-85ff-ce16bb5eee29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Séparation de 32 fichiers en 4 listes en 0.0s de taille [8, 8, 8, 8]\n"
     ]
    }
   ],
   "source": [
    "filenames_splits = divide_filenames_into_splits(filenames=fichiers, num_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "618e2c0e-ed24-40b0-8b1d-657eee974bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                            | 0/8 [00:00<?, ?it/s]\n",
      "\u001b[A%|                                                                            | 0/8 [00:00<?, ?it/s]\n",
      "\n",
      "\u001b[A\u001b[A                                                                           | 0/8 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                                                                        | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load file data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7f51444376e0 state=finished raised DependencyError>]. Skipping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 8/8 [13:37<00:00, 102.24s/it]\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████| 8/8 [13:37<00:00, 102.24s/it]\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████| 8/8 [13:37<00:00, 102.24s/it]\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████| 8/8 [13:37<00:00, 102.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Création de 4207 documents en 817.9594793319702s.\n",
      "Sun Feb  9 23:41:10 2025    ./profiling/stats_parallel_async_load_with_4_split_jobs\n",
      "\n",
      "         1820628370 function calls (1817709540 primitive calls) in 817.967 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 680 to 15 due to restriction <15>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "  271/269    0.141    0.001  825.651    3.069 nest_asyncio.py:100(_run_once)\n",
      "    42/41    0.000    0.000  817.965   19.950 tasks.py:291(__step)\n",
      "    42/41    0.000    0.000  817.964   19.950 tasks.py:308(__step_run_and_handle_result)\n",
      "    42/41    0.000    0.000  817.963   19.950 {method 'send' of 'coroutine' objects}\n",
      "   356/69    0.001    0.000  817.958   11.854 events.py:86(_run)\n",
      "   355/69    0.001    0.000  817.958   11.854 {method 'run' of '_contextvars.Context' objects}\n",
      "       32    0.000    0.000  817.937   25.561 asyncio.py:75(wrap_awaitable)\n",
      "       32    0.001    0.000  817.915   25.560 base.py:594(aload_file)\n",
      "       32    0.000    0.000  817.782   25.556 base.py:38(aload_data)\n",
      "       32    0.000    0.000  817.781   25.556 __init__.py:328(wrapped_f)\n",
      "       32    0.001    0.000  817.311   25.541 __init__.py:465(__call__)\n",
      "       34    0.066    0.002  810.391   23.835 base.py:36(load_data)\n",
      "     4207    2.593    0.001  804.814    0.191 _page.py:2266(extract_text)\n",
      "4345/4207   13.209    0.003  792.716    0.188 _page.py:1822(_extract_text)\n",
      "     4345    0.028    0.000  572.246    0.132 _data_structures.py:1418(operations)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x7f514cc74410>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs = [SimpleDirectoryReader(input_files=split).aload_data(show_progress=True) for split in filenames_splits]\n",
    "\n",
    "profiler = cProfile.Profile()\n",
    "\n",
    "tic = time.time()\n",
    "profiler.enable()\n",
    "results = await asyncio.gather(*jobs)\n",
    "nodes = []\n",
    "for result in results:\n",
    "  nodes.extend(result)\n",
    "profiler.disable()\n",
    "print(f\"\\nCréation de {len(documents)} documents en {time.time()-tic}s.\")\n",
    "\n",
    "profiler.dump_stats('./profiling/stats_parallel_async_load_with_4_split_jobs')\n",
    "p = pstats.Stats(\"./profiling/stats_parallel_async_load_with_4_split_jobs\")\n",
    "p.strip_dirs().sort_stats(SortKey.CUMULATIVE).print_stats(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "022c1979-3176-4bf6-804b-07df5a8d3fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load file data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7f5142c42600 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7f512d95f9e0 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7f5126f41220 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7f5120bd5700 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7f5119e2e4e0 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7f51135d3680 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7f510d0bec30 state=finished raised DependencyError>]. Skipping...\n",
      "Temps d'exécution moyen du pipeline sur 7 ittérations : 207.1110 secondes\n"
     ]
    }
   ],
   "source": [
    "# Define the async function to be timed\n",
    "async def run_pipeline(filenames_splits):\n",
    "    jobs = [SimpleDirectoryReader(input_files=split).aload_data() for split in filenames_splits]\n",
    "    await asyncio.gather(*jobs)\n",
    "\n",
    "# Use timeit to measure the execution time\n",
    "time_taken = timeit.timeit(lambda: asyncio.run(run_pipeline(filenames_splits)), number=7)\n",
    "print(f\"Temps d'exécution moyen du pipeline sur 7 ittérations : {time_taken / 7:.4f} secondes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af053475-6dc7-42eb-a0df-80eeaf2aa4f6",
   "metadata": {},
   "source": [
    "#### b) 8 splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7b754cca-b1f5-4872-85f1-b28b278496fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Séparation de 32 fichiers en 8 listes en 0.0s de taille [4, 4, 4, 4, 4, 4, 4, 4]\n"
     ]
    }
   ],
   "source": [
    "filenames_splits = divide_filenames_into_splits(filenames=fichiers, num_jobs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9314cbc6-af70-4609-b5d7-4d8789a1d247",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                            | 0/4 [00:00<?, ?it/s]\n",
      "\u001b[A%|                                                                            | 0/4 [00:00<?, ?it/s]\n",
      "\n",
      "\u001b[A\u001b[A                                                                           | 0/4 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                                                                        | 0/4 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A                                                                     | 0/4 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A                                                                  | 0/4 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A                                                               | 0/4 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A                                                            | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load file data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7f514cb190d0 state=finished raised DependencyError>]. Skipping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 4/4 [13:44<00:00, 206.19s/it]\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████| 4/4 [13:44<00:00, 206.19s/it]\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████| 4/4 [13:44<00:00, 206.19s/it]\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████| 4/4 [13:44<00:00, 206.19s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████| 4/4 [13:44<00:00, 206.19s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████| 4/4 [13:44<00:00, 206.19s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████| 4/4 [13:44<00:00, 206.19s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████| 4/4 [13:44<00:00, 206.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Création de 4207 documents en 824.8368690013885s.\n",
      "Mon Feb 10 00:19:07 2025    ./profiling/stats_parallel_async_load_with_8_split_jobs\n",
      "\n",
      "         1820670062 function calls (1817750127 primitive calls) in 824.822 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 669 to 15 due to restriction <15>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "  437/435    0.125    0.000  889.988    2.046 nest_asyncio.py:100(_run_once)\n",
      "       49    0.000    0.000  824.892   16.835 tasks.py:291(__step)\n",
      "       49    0.000    0.000  824.891   16.835 tasks.py:308(__step_run_and_handle_result)\n",
      "       49    0.001    0.000  824.887   16.834 {method 'send' of 'coroutine' objects}\n",
      "   527/67    0.001    0.000  824.836   12.311 events.py:86(_run)\n",
      "   526/67    0.002    0.000  824.836   12.311 {method 'run' of '_contextvars.Context' objects}\n",
      "       32    0.000    0.000  824.776   25.774 asyncio.py:75(wrap_awaitable)\n",
      "       32    0.001    0.000  824.728   25.773 base.py:594(aload_file)\n",
      "       32    0.000    0.000  824.645   25.770 base.py:38(aload_data)\n",
      "       32    0.000    0.000  824.645   25.770 __init__.py:328(wrapped_f)\n",
      "       32    0.001    0.000  824.644   25.770 __init__.py:465(__call__)\n",
      "     4207    2.514    0.001  810.870    0.193 _page.py:2266(extract_text)\n",
      "4345/4207   13.238    0.003  801.805    0.191 _page.py:1822(_extract_text)\n",
      "       34    0.062    0.002  697.707   20.521 base.py:36(load_data)\n",
      "     4345    0.029    0.000  575.292    0.132 _data_structures.py:1418(operations)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x7f5143bfd130>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs = [SimpleDirectoryReader(input_files=split).aload_data(show_progress=True) for split in filenames_splits]\n",
    "\n",
    "profiler = cProfile.Profile()\n",
    "\n",
    "tic = time.time()\n",
    "profiler.enable()\n",
    "results = await asyncio.gather(*jobs)\n",
    "nodes = []\n",
    "for result in results:\n",
    "  nodes.extend(result)\n",
    "profiler.disable()\n",
    "print(f\"\\nCréation de {len(documents)} documents en {time.time()-tic}s.\")\n",
    "\n",
    "profiler.dump_stats('./profiling/stats_parallel_async_load_with_8_split_jobs')\n",
    "p = pstats.Stats(\"./profiling/stats_parallel_async_load_with_8_split_jobs\")\n",
    "p.strip_dirs().sort_stats(SortKey.CUMULATIVE).print_stats(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b8102fe6-0fa7-4b69-9ff4-031d1791b2a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load file data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7f5141ea03e0 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7f511ff28c80 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7f512e5f7e00 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7f51265d2810 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7f511e06fb00 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7f5115928590 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7f510d3691c0 state=finished raised DependencyError>]. Skipping...\n",
      "Temps d'exécution moyen du pipeline sur 7 ittérations : 206.2378 secondes\n"
     ]
    }
   ],
   "source": [
    "# Define the async function to be timed\n",
    "async def run_pipeline(filenames_splits):\n",
    "    jobs = [SimpleDirectoryReader(input_files=split).aload_data() for split in filenames_splits]\n",
    "    await asyncio.gather(*jobs)\n",
    "\n",
    "# Use timeit to measure the execution time\n",
    "time_taken = timeit.timeit(lambda: asyncio.run(run_pipeline(filenames_splits)), number=7)\n",
    "print(f\"Temps d'exécution moyen du pipeline sur 7 ittérations : {time_taken / 7:.4f} secondes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "B5kFPMi3l-Kd",
   "metadata": {
    "id": "B5kFPMi3l-Kd"
   },
   "source": [
    "### Conclusion chargement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d8df94-2c10-47ef-9034-8d9155922521",
   "metadata": {},
   "source": [
    "  Méthode       | Num_proc | Temps moyen |\n",
    " |---------------|----------|-------------|\n",
    " | Séquentiel     | 1        | 3min43s ±11s   |\n",
    " | Parallèle     | 4 workers       | 1min41s ±6s  |\n",
    " | Parallèle     | 8 workers       | 1min37s ±3s  |\n",
    " | Asynchrone     | 1        | 3min52s   |\n",
    " | Asynchrone/Parallèle     | 4 workers        | 3min51s ±29s  |\n",
    " | Asynchrone/Parallèl     | 8 workers        | 3min34s ± 6s   |\n",
    " | Asynchrone/Jobs multiple     | 4 jobs       | 3min27s  |\n",
    " | Asynchrone/Jobs multiple     | 8 jobs       | 3min26s   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b00be91-22ea-403c-b9c4-cd030b7e6c09",
   "metadata": {
    "id": "5b00be91-22ea-403c-b9c4-cd030b7e6c09"
   },
   "source": [
    "## 2. Pipeline de traitement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VTdmVzilKVdk",
   "metadata": {
    "id": "VTdmVzilKVdk"
   },
   "source": [
    "#### Définition du pipeline d'ingestion :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1089adee-bc8a-457f-8d96-113435923d10",
   "metadata": {
    "id": "1089adee-bc8a-457f-8d96-113435923d10"
   },
   "outputs": [],
   "source": [
    "from llama_index.core import Document\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "# create the pipeline with transformations\n",
    "pipeline = IngestionPipeline(\n",
    "    transformations=[\n",
    "        SentenceSplitter(chunk_size=512, chunk_overlap=20),\n",
    "        HuggingFaceEmbedding(\"BAAI/bge-small-en-v1.5\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# since we'll be testing performance, using timeit and cProfile\n",
    "# we're going to disable cache\n",
    "pipeline.disable_cache = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e345d8-0524-4e1b-8d11-88a2a916196e",
   "metadata": {
    "id": "20e345d8-0524-4e1b-8d11-88a2a916196e"
   },
   "source": [
    "### 2.1 Exécution séquentielle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80091185-d7ac-4ff2-aba4-e1ba5546a865",
   "metadata": {
    "id": "80091185-d7ac-4ff2-aba4-e1ba5546a865"
   },
   "source": [
    "By default `num_workers` is set to `None` and this will invoke sequential execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9b31aabf-da4d-4a4a-b92c-2b83a75b296a",
   "metadata": {
    "id": "9b31aabf-da4d-4a4a-b92c-2b83a75b296a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96af3313a82d406e99adb3ec7b008522",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/4207 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0edf1352c7349edb087d6028c84ed0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/9216 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Création de 9216 nodes en 42.28653264045715s.\n",
      "Mon Feb 10 00:49:14 2025    ./profiling/stats_sequential_ingestion\n",
      "\n",
      "         39007488 function calls (37398798 primitive calls) in 211.433 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 865 to 15 due to restriction <15>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "      3/2    0.000    0.000  211.432  105.716 interactiveshell.py:3543(run_code)\n",
      "      3/2    0.000    0.000  211.432  105.716 {built-in method builtins.exec}\n",
      "      2/1    0.001    0.000  211.432  211.432 3387206633.py:1(<module>)\n",
      "   4213/1    0.098    0.000  211.431  211.431 dispatcher.py:253(wrapper)\n",
      "        1    0.000    0.000  211.431  211.431 pipeline.py:451(run)\n",
      "        1    0.000    0.000  211.431  211.431 pipeline.py:69(run_transformations)\n",
      "     2243    0.023    0.000  205.799    0.092 nest_asyncio.py:100(_run_once)\n",
      "        1    0.041    0.041  200.549  200.549 base.py:305(get_text_embedding_batch)\n",
      "      922    0.002    0.000  199.499    0.216 base.py:308(_get_text_embeddings)\n",
      "      922    0.003    0.000  199.498    0.216 base.py:239(_embed)\n",
      "      922    0.007    0.000  199.495    0.216 __init__.py:328(wrapped_f)\n",
      "      922    0.009    0.000  199.341    0.216 __init__.py:465(__call__)\n",
      "      922    0.026    0.000  195.501    0.212 base.py:191(_embed_with_retry)\n",
      "      922    0.253    0.000  195.366    0.212 SentenceTransformer.py:461(encode)\n",
      "      922  146.514    0.159  146.514    0.159 {method 'cpu' of 'torch._C.TensorBase' objects}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x7f5126fdccb0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profiler = cProfile.Profile()\n",
    "\n",
    "tic = time.time()\n",
    "profiler.enable()\n",
    "nodes = pipeline.run(documents=documents, show_progress=True)\n",
    "profiler.disable()\n",
    "print(f\"\\nCréation de {len(nodes)} nodes en {(time.time()-tic)/5}s.\")\n",
    "\n",
    "profiler.dump_stats('./profiling/stats_sequential_ingestion')\n",
    "p = pstats.Stats(\"./profiling/stats_sequential_ingestion\")\n",
    "p.strip_dirs().sort_stats(SortKey.CUMULATIVE).print_stats(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1ac8b9c1-9129-43e6-9d7d-cd50b3abc953",
   "metadata": {
    "id": "1ac8b9c1-9129-43e6-9d7d-cd50b3abc953"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps d'exécution moyen du pipeline sur 7 ittérations :\n",
      "3min 10s ± 208 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Temps d'exécution moyen du pipeline sur 7 ittérations :\")\n",
    "%timeit pipeline.run(documents=documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1937fbaa-0cef-494d-b3e1-a5ff268fd8d2",
   "metadata": {
    "id": "1937fbaa-0cef-494d-b3e1-a5ff268fd8d2"
   },
   "source": [
    "### 2.2 Exécution parallèle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf20d688-5994-4cd7-8f52-079b686328fb",
   "metadata": {
    "id": "cf20d688-5994-4cd7-8f52-079b686328fb"
   },
   "source": [
    "A single run. Setting `num_workers` to a value greater than 1 will invoke parallel execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b5d68e6a-a658-46e8-9b71-d857b1c90d50",
   "metadata": {
    "id": "b5d68e6a-a658-46e8-9b71-d857b1c90d50"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Removing unpickleable private attribute _chunking_tokenizer_fn\n",
      "WARNING:root:Removing unpickleable private attribute _split_fns\n",
      "WARNING:root:Removing unpickleable private attribute _sub_sentence_split_fns\n",
      "WARNING:root:Removing unpickleable private attribute _chunking_tokenizer_fn\n",
      "WARNING:root:Removing unpickleable private attribute _split_fns\n",
      "WARNING:root:Removing unpickleable private attribute _sub_sentence_split_fns\n",
      "WARNING:root:Removing unpickleable private attribute _chunking_tokenizer_fn\n",
      "WARNING:root:Removing unpickleable private attribute _split_fns\n",
      "WARNING:root:Removing unpickleable private attribute _sub_sentence_split_fns\n",
      "WARNING:root:Removing unpickleable private attribute _chunking_tokenizer_fn\n",
      "WARNING:root:Removing unpickleable private attribute _split_fns\n",
      "WARNING:root:Removing unpickleable private attribute _sub_sentence_split_fns\n",
      "WARNING:root:Removing unpickleable private attribute _chunking_tokenizer_fn\n",
      "WARNING:root:Removing unpickleable private attribute _split_fns\n",
      "WARNING:root:Removing unpickleable private attribute _sub_sentence_split_fns\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Création de 9216 nodes en 67.03065361976624s.\n",
      "Mon Feb 10 01:20:12 2025    ./profiling/stats_parallel_ingestion_worker4\n",
      "\n",
      "         666884 function calls (664767 primitive calls) in 335.153 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 712 to 15 due to restriction <15>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "      332  293.430    0.884  628.581    1.893 {built-in method time.sleep}\n",
      "     1704    0.007    0.000  613.721    0.360 pool.py:500(_wait_for_updates)\n",
      "     3411    0.017    0.000  340.250    0.100 connection.py:1122(wait)\n",
      "     3411    0.014    0.000  340.167    0.100 selectors.py:402(select)\n",
      "     3411    1.338    0.000  338.610    0.099 {method 'poll' of 'select.poll' objects}\n",
      "      3/2    0.000    0.000  335.151  167.576 {built-in method builtins.exec}\n",
      "      2/1    0.120    0.060  335.151  335.151 2641836050.py:1(<module>)\n",
      "      2/1    0.000    0.000  335.031  335.031 dispatcher.py:253(wrapper)\n",
      "        1    0.000    0.000  335.030  335.030 pipeline.py:451(run)\n",
      "        1    0.000    0.000  335.030  335.030 pool.py:738(__exit__)\n",
      "        1    0.000    0.000  335.030  335.030 pool.py:654(terminate)\n",
      "       11    0.000    0.000  335.011   30.456 util.py:208(__call__)\n",
      "        1    0.000    0.000  335.009  335.009 pool.py:680(_terminate_pool)\n",
      "     1707    0.002    0.000  334.893    0.196 connection.py:253(poll)\n",
      "     1707    0.002    0.000  334.890    0.196 connection.py:439(_poll)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x7f514c329880>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profiler = cProfile.Profile()\n",
    "\n",
    "tic = time.time()\n",
    "profiler.enable()\n",
    "nodes = pipeline.run(documents=documents, num_workers=4, show_progress=True)\n",
    "profiler.disable()\n",
    "print(f\"\\nCréation de {len(nodes)} nodes en {(time.time()-tic)/5}s.\")\n",
    "\n",
    "profiler.dump_stats('./profiling/stats_parallel_ingestion_worker4')\n",
    "p = pstats.Stats(\"./profiling/stats_parallel_ingestion_worker4\")\n",
    "p.strip_dirs().sort_stats(SortKey.CUMULATIVE).print_stats(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8bffaefb-f710-4187-a19f-11d10ebae82b",
   "metadata": {
    "id": "8bffaefb-f710-4187-a19f-11d10ebae82b"
   },
   "outputs": [],
   "source": [
    "# Méthode la moins performante, on la commente pour perdre moins de temps\n",
    "# print(f\"Temps d'exécution moyen du pipeline sur 7 ittérations :\")\n",
    "# %timeit pipeline.run(documents=documents, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b404fef3-ea1c-4b38-a558-c5be27bdd9f7",
   "metadata": {
    "id": "b404fef3-ea1c-4b38-a558-c5be27bdd9f7"
   },
   "source": [
    "### 2.3 Exécution asynchrone sur un processeur"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7b8e77-199c-4afc-870d-91fafc112f8e",
   "metadata": {
    "id": "eb7b8e77-199c-4afc-870d-91fafc112f8e"
   },
   "source": [
    "As with the sync case, `num_workers` is default to `None`, which will then lead to single-batch execution of async tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dca073ac-ed85-4d29-821e-2acf37ea5525",
   "metadata": {
    "id": "dca073ac-ed85-4d29-821e-2acf37ea5525"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6da0b6133a3e45b8a04d929b9007c57b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/4207 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings: 100%|█████████████████████████████████████████| 922/922 [03:56<00:00,  3.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Création de 9216 nodes en 49.40059442520142s.\n",
      "Mon Feb 10 01:24:20 2025    ./profiling/stats_async_ingestion\n",
      "\n",
      "         163838182 function calls (150670398 primitive calls) in 246.998 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 850 to 15 due to restriction <15>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "13424/9217    0.250    0.000  244.788    0.027 dispatcher.py:253(wrapper)\n",
      "21522/21462    0.022    0.000  236.541    0.011 events.py:86(_run)\n",
      "21522/21462    0.019    0.000  236.517    0.011 {method 'run' of '_contextvars.Context' objects}\n",
      "    11061    0.045    0.000  236.319    0.021 tasks.py:291(__step)\n",
      "    11061    0.059    0.000  236.250    0.021 tasks.py:308(__step_run_and_handle_result)\n",
      "    11060    0.024    0.000  235.736    0.021 {method 'send' of 'coroutine' objects}\n",
      "     9216    0.099    0.000  235.214    0.026 base.py:284(_aget_text_embedding)\n",
      "     9216    0.024    0.000  233.932    0.025 base.py:296(_get_text_embedding)\n",
      "     9216    0.023    0.000  233.908    0.025 base.py:239(_embed)\n",
      "     9216    0.057    0.000  233.885    0.025 __init__.py:328(wrapped_f)\n",
      "     9216    0.075    0.000  233.644    0.025 __init__.py:465(__call__)\n",
      "     9216    0.176    0.000  232.624    0.025 base.py:191(_embed_with_retry)\n",
      "     9216    0.972    0.000  232.243    0.025 SentenceTransformer.py:461(encode)\n",
      "     9216    0.141    0.000  106.855    0.012 SentenceTransformer.py:683(forward)\n",
      "2009088/27648    3.086    0.000  106.628    0.004 module.py:1735(_wrapped_call_impl)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x7f511dbf6f00>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profiler = cProfile.Profile()\n",
    "\n",
    "tic = time.time()\n",
    "profiler.enable()\n",
    "nodes = await pipeline.arun(documents=documents, show_progress=True)\n",
    "profiler.disable()\n",
    "print(f\"\\nCréation de {len(nodes)} nodes en {(time.time()-tic)/5}s.\")\n",
    "\n",
    "profiler.dump_stats('./profiling/stats_async_ingestion')\n",
    "p = pstats.Stats(\"./profiling/stats_async_ingestion\")\n",
    "p.strip_dirs().sort_stats(SortKey.CUMULATIVE).print_stats(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bb37efa7-3936-4cf8-a029-fcba95205218",
   "metadata": {
    "id": "bb37efa7-3936-4cf8-a029-fcba95205218"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps d'exécution moyen du pipeline sur 7 ittérations :\n",
      "3min 20s ± 1.22 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "loop = asyncio.get_event_loop()\n",
    "print(f\"Temps d'exécution moyen du pipeline sur 7 ittérations :\")\n",
    "%timeit loop.run_until_complete(pipeline.arun(documents=documents))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f482139e-1d0b-41ac-bff0-0c4a86a3ce62",
   "metadata": {
    "id": "f482139e-1d0b-41ac-bff0-0c4a86a3ce62"
   },
   "source": [
    "### 2.4 Exécution asynchrone sur plusieurs processeurs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1e3ede-1ff4-430c-abfb-270be055ff71",
   "metadata": {
    "id": "4b1e3ede-1ff4-430c-abfb-270be055ff71"
   },
   "source": [
    "Here the `ProcessPoolExecutor` from `concurrent.futures` is used to execute processes asynchronously. The tasks are being processed are blocking, but also performed asynchronously on the individual processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3ce7856e-66ee-44ac-94c6-85082d75d327",
   "metadata": {
    "id": "3ce7856e-66ee-44ac-94c6-85082d75d327"
   },
   "outputs": [],
   "source": [
    "# profiler = cProfile.Profile()\n",
    "\n",
    "# tic = time.time()\n",
    "# profiler.enable()\n",
    "# nodes = await pipeline.arun(documents=documents, num_workers=4, show_progress=True)\n",
    "# profiler.disable()\n",
    "# print(f\"\\nCréation de {len(nodes)} nodes en {(time.time()-tic)/5}s.\")\n",
    "\n",
    "# profiler.dump_stats('./profiling/stats_parallel_async_ingestion_worker4')\n",
    "# p = pstats.Stats(\"./profiling/stats_parallel_async_ingestion_worker4\")\n",
    "# p.strip_dirs().sort_stats(SortKey.CUMULATIVE).print_stats(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47f00aa-d19a-4b1a-92c3-8ddabdbd13ba",
   "metadata": {},
   "source": [
    "...\n",
    "\n",
    "RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method\n",
    "\n",
    "...\n",
    "\n",
    "BrokenProcessPool: A process in the process pool was terminated abruptly while the future was running or pending."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a0a0bf6c-510c-44b3-b9f6-570593321817",
   "metadata": {
    "id": "a0a0bf6c-510c-44b3-b9f6-570593321817"
   },
   "outputs": [],
   "source": [
    "# loop = asyncio.get_event_loop()\n",
    "# print(f\"Temps d'exécution moyen du pipeline sur 7 ittérations :\")\n",
    "# %timeit loop.run_until_complete(pipeline.arun(documents=documents, num_workers=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5057e4b-e79d-46a7-90cf-1035b54c69fb",
   "metadata": {},
   "source": [
    "### 2.5 Exécution asynchrone avec des documents par lots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fe92be8f-3b72-4700-ae3a-09df431b88f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_documents_into_splits(documents, num_jobs):\n",
    "    tic = time.time()\n",
    "    documents_splits = [documents[i::num_jobs] for i in range(num_jobs)]\n",
    "    print(f\"Séparation de {len(documents)} documents en {num_jobs} listes en {round(time.time()-tic, 2)}s de taille {[len(job) for job in documents_splits]}\")\n",
    "    return documents_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9ca59a-0cd1-44c0-9294-0446bc9aa267",
   "metadata": {},
   "source": [
    "#### a) 4 splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cd168e82-10d6-4f20-a65f-4e9889f3c0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Séparation de 4207 documents en 4 listes en 0.0s de taille [1052, 1052, 1052, 1051]\n"
     ]
    }
   ],
   "source": [
    "documents_splits = divide_documents_into_splits(documents=documents, num_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b6b2d7ec-ee83-4dc6-b7a8-f41274f8e5c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf50824f30ff47308382cc651cc124ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/1052 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|                                                   | 0/232 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d967fac98a334f0eacc89626030fac67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/1052 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aerating embeddings:   0%|                                                   | 0/230 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fdf77fdab1d47a9b60a2be4285f6681",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/1052 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[A\u001b[Ating embeddings:   0%|                                                   | 0/230 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50204b61864c4cefabd2c4de92c35732",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/1051 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Generating embeddings: 100%|█████████████████████████████████████████| 232/232 [04:04<00:00,  1.06s/it]\n",
      "\n",
      "Generating embeddings: 100%|█████████████████████████████████████████| 230/230 [04:02<00:00,  1.06s/it]\n",
      "\n",
      "\n",
      "Generating embeddings: 100%|█████████████████████████████████████████| 230/230 [04:00<00:00,  1.05s/it]\n",
      "\n",
      "\n",
      "\n",
      "Generating embeddings: 100%|█████████████████████████████████████████| 231/231 [03:58<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Création de 9216 nodes en 49.52480459213257s.\n",
      "Mon Feb 10 01:55:12 2025    ./profiling/stats_parallel_async_ingestion_with_4_split_jobs\n",
      "\n",
      "         164002373 function calls (150827547 primitive calls) in 247.571 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 851 to 15 due to restriction <15>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "  481/478    0.051    0.000  257.725    0.539 nest_asyncio.py:100(_run_once)\n",
      "21707/21181    0.032    0.000  247.553    0.012 events.py:86(_run)\n",
      "13427/9220    0.254    0.000  245.390    0.027 dispatcher.py:253(wrapper)\n",
      "21707/21181    0.019    0.000  238.576    0.011 {method 'run' of '_contextvars.Context' objects}\n",
      "    11071    0.042    0.000  238.566    0.022 tasks.py:291(__step)\n",
      "    11071    0.058    0.000  238.499    0.022 tasks.py:308(__step_run_and_handle_result)\n",
      "    11070    0.022    0.000  238.234    0.022 {method 'send' of 'coroutine' objects}\n",
      "     9216    0.100    0.000  237.350    0.026 base.py:284(_aget_text_embedding)\n",
      "     9216    0.025    0.000  236.063    0.026 base.py:296(_get_text_embedding)\n",
      "     9216    0.023    0.000  236.038    0.026 base.py:239(_embed)\n",
      "     9216    0.059    0.000  236.015    0.026 __init__.py:328(wrapped_f)\n",
      "     9216    0.078    0.000  235.770    0.026 __init__.py:465(__call__)\n",
      "     9216    0.183    0.000  234.704    0.025 base.py:191(_embed_with_retry)\n",
      "     9216    0.983    0.000  234.327    0.025 SentenceTransformer.py:461(encode)\n",
      "     9216    0.147    0.000  109.262    0.012 SentenceTransformer.py:683(forward)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x7f514640a8d0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs = [pipeline.arun(documents=split, show_progress=True) for split in documents_splits]\n",
    "\n",
    "profiler = cProfile.Profile()\n",
    "\n",
    "tic = time.time()\n",
    "profiler.enable()\n",
    "results = await asyncio.gather(*jobs)\n",
    "nodes = []\n",
    "for result in results:\n",
    "  nodes.extend(result)\n",
    "profiler.disable()\n",
    "print(f\"\\nCréation de {len(nodes)} nodes en {(time.time()-tic)/5}s.\")\n",
    "\n",
    "profiler.dump_stats('./profiling/stats_parallel_async_ingestion_with_4_split_jobs')\n",
    "p = pstats.Stats(\"./profiling/stats_parallel_async_ingestion_with_4_split_jobs\")\n",
    "p.strip_dirs().sort_stats(SortKey.CUMULATIVE).print_stats(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c667e91e-64cf-4d93-b92d-e3cff1b3d0c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps d'exécution moyen du pipeline sur 7 ittérations : 202.3494 secondes\n"
     ]
    }
   ],
   "source": [
    "# Define the async function to be timed\n",
    "async def run_pipeline(documents_splits):\n",
    "    jobs = [pipeline.arun(documents=split) for split in documents_splits]\n",
    "    await asyncio.gather(*jobs)\n",
    "\n",
    "# Use timeit to measure the execution time\n",
    "time_taken = timeit.timeit(lambda: asyncio.run(run_pipeline(documents_splits)), number=7)\n",
    "print(f\"Temps d'exécution moyen du pipeline sur 7 ittérations : {time_taken / 7:.4f} secondes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ee9304-90c9-4c76-b281-ed2aac9bff8e",
   "metadata": {},
   "source": [
    "#### b) 8 splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a8974cf0-0825-4a83-96d8-81006cd61d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Séparation de 4207 documents en 8 listes en 0.0s de taille [526, 526, 526, 526, 526, 526, 526, 525]\n"
     ]
    }
   ],
   "source": [
    "documents_splits = divide_documents_into_splits(documents=documents, num_jobs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bf7b2d42-56a9-4956-91d3-367da8c779a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f0bcbd133e94a4eacf0ae9f5d89dc7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/526 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|                                                   | 0/117 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8dcc97d1255417592fe4372c0a52aa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/526 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aerating embeddings:   0%|                                                   | 0/115 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67f4666006af4402bd6ccf23e0c97d3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/526 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[A\u001b[Ating embeddings:   0%|                                                   | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f8dfcadc9aa4ac6a48dcfbd70ba4f0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/526 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[Ag embeddings:   0%|                                                   | 0/117 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36720f6749b84e6cbb3d630b6fa8d067",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/526 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[Ambeddings:   0%|                                                   | 0/115 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "924aca059e6d41b1a9d1744acfc57d4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/526 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[Addings:   0%|                                                   | 0/116 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35521ebd8af143c581d3787c85d3d83f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/526 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[Angs:   0%|                                                   | 0/118 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3e28e027e1247529323f92b5741f782",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/525 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Generating embeddings: 100%|█████████████████████████████████████████| 117/117 [04:03<00:00,  2.08s/it]\n",
      "\n",
      "Generating embeddings: 100%|█████████████████████████████████████████| 115/115 [04:02<00:00,  2.11s/it]\n",
      "\n",
      "\n",
      "Generating embeddings: 100%|█████████████████████████████████████████| 113/113 [04:01<00:00,  2.14s/it]\n",
      "\n",
      "\n",
      "\n",
      "Generating embeddings: 100%|█████████████████████████████████████████| 117/117 [03:59<00:00,  2.05s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Generating embeddings: 100%|█████████████████████████████████████████| 115/115 [03:58<00:00,  2.08s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Generating embeddings: 100%|█████████████████████████████████████████| 116/116 [03:57<00:00,  2.05s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Generating embeddings: 100%|█████████████████████████████████████████| 118/118 [03:56<00:00,  2.00s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Generating embeddings: 100%|█████████████████████████████████████████| 114/114 [03:55<00:00,  2.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Création de 9216 nodes en 48.99229469299316s.\n",
      "Mon Feb 10 02:22:54 2025    ./profiling/stats_parallel_async_ingestion_with_8_split_jobs\n",
      "\n",
      "         164226142 function calls (151043239 primitive calls) in 244.924 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 847 to 15 due to restriction <15>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "  707/705    0.055    0.000  254.292    0.361 nest_asyncio.py:100(_run_once)\n",
      "11084/11083    0.044    0.000  246.089    0.022 tasks.py:291(__step)\n",
      "    11083    0.061    0.000  244.896    0.022 tasks.py:308(__step_run_and_handle_result)\n",
      "21953/21199    0.036    0.000  244.889    0.012 events.py:86(_run)\n",
      "21953/21199    0.023    0.000  244.866    0.012 {method 'run' of '_contextvars.Context' objects}\n",
      "    11083    0.023    0.000  244.708    0.022 {method 'send' of 'coroutine' objects}\n",
      "13431/9224    0.229    0.000  242.197    0.026 dispatcher.py:253(wrapper)\n",
      "     9216    0.101    0.000  234.602    0.025 base.py:284(_aget_text_embedding)\n",
      "     9216    0.026    0.000  233.335    0.025 base.py:296(_get_text_embedding)\n",
      "     9216    0.021    0.000  233.310    0.025 base.py:239(_embed)\n",
      "     9216    0.059    0.000  233.288    0.025 __init__.py:328(wrapped_f)\n",
      "     9216    0.079    0.000  233.044    0.025 __init__.py:465(__call__)\n",
      "     9216    0.185    0.000  232.022    0.025 base.py:191(_embed_with_retry)\n",
      "     9216    1.009    0.000  231.678    0.025 SentenceTransformer.py:461(encode)\n",
      "     9216    0.148    0.000  102.711    0.011 SentenceTransformer.py:683(forward)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x7f51261968d0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs = [pipeline.arun(documents=split, show_progress=True) for split in documents_splits]\n",
    "\n",
    "profiler = cProfile.Profile()\n",
    "\n",
    "tic = time.time()\n",
    "profiler.enable()\n",
    "results = await asyncio.gather(*jobs)\n",
    "nodes = []\n",
    "for result in results:\n",
    "  nodes.extend(result)\n",
    "profiler.disable()\n",
    "print(f\"\\nCréation de {len(nodes)} nodes en {(time.time()-tic)/5}s.\")\n",
    "\n",
    "profiler.dump_stats('./profiling/stats_parallel_async_ingestion_with_8_split_jobs')\n",
    "p = pstats.Stats(\"./profiling/stats_parallel_async_ingestion_with_8_split_jobs\")\n",
    "p.strip_dirs().sort_stats(SortKey.CUMULATIVE).print_stats(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5eb55432-f60b-4158-9719-b17a3327d8aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps d'exécution moyen du pipeline sur 7 ittérations : 199.2023 secondes\n"
     ]
    }
   ],
   "source": [
    "# Define the async function to be timed\n",
    "async def run_pipeline(documents_splits):\n",
    "    jobs = [pipeline.arun(documents=split) for split in documents_splits]\n",
    "    await asyncio.gather(*jobs)\n",
    "\n",
    "# Use timeit to measure the execution time\n",
    "time_taken = timeit.timeit(lambda: asyncio.run(run_pipeline(documents_splits)), number=7)\n",
    "print(f\"Temps d'exécution moyen du pipeline sur 7 ittérations : {time_taken / 7:.4f} secondes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9bfb79-2def-462c-b3bb-d446e3bb9463",
   "metadata": {
    "id": "5c9bfb79-2def-462c-b3bb-d446e3bb9463"
   },
   "source": [
    "### Conclusion Pipeline ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702e90d6-013a-43d6-8c49-dbd78709587a",
   "metadata": {
    "id": "702e90d6-013a-43d6-8c49-dbd78709587a"
   },
   "source": [
    "I'm inclined to remove multi-processing from the ingestion pipeline. It creates more issues than it solves, async is enough (and a lot safer)\n",
    "\n",
    "\n",
    "  Méthode       | Num_proc | Temps moyen |\n",
    " |---------------|----------|-------------|\n",
    " | Séquentiel     | 1        | 3min10s ± 2s   |\n",
    " | Parallèle     | 4 workers       | 5min35s  |\n",
    " | Asynchrone     | 1        | 3min20s ± 1s   |\n",
    " | Asynchrone/Parallèle     | 4 workers        | Error  |\n",
    " | Asynchrone/Jobs multiple     | 4 jobs       | 3min22s  |\n",
    " | Asynchrone/Jobs multiple     | 8 jobs       | 3min19s   |\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "env_llamaindex",
   "language": "python",
   "name": "env_llamaindex"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
