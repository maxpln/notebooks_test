{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1de0f1a",
   "metadata": {
    "id": "d1de0f1a"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/docs/examples/ingestion/parallel_execution_ingestion_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cbe152-de29-4240-8e13-f74dc146a658",
   "metadata": {
    "id": "c8cbe152-de29-4240-8e13-f74dc146a658"
   },
   "source": [
    "# Parallelizing llamaindex RAG Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-ElrAEOGDSHt",
   "metadata": {
    "id": "-ElrAEOGDSHt"
   },
   "source": [
    "## 0. Pré-requis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef3ff0cf-4859-4de0-9238-aca8e2903ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install llama-index-cli\n",
    "#%pip install llama-index-embeddings-openai\n",
    "#%pip install llama-index-readers-file\n",
    "#%pip install llama-index-embeddings-huggingface\n",
    "#%pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0963707-6ebe-4441-a363-1bfb48ce9df3",
   "metadata": {
    "id": "e0963707-6ebe-4441-a363-1bfb48ce9df3"
   },
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ebec124-1aaf-4181-a0e0-93c09bb644d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile, pstats\n",
    "from pstats import SortKey\n",
    "import time\n",
    "import asyncio\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2VVToRRpCjTh",
   "metadata": {
    "id": "2VVToRRpCjTh"
   },
   "source": [
    "### Téléchargement des données\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92686bb0-85ed-4bb3-99eb-f5fc6c100787",
   "metadata": {
    "id": "92686bb0-85ed-4bb3-99eb-f5fc6c100787"
   },
   "source": [
    "For this notebook, we'll load the `PatronusAIFinanceBenchDataset` llama-dataset from [llamahub](https://llamahub.ai)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3b94d62-efa4-479a-9215-e094b5a73061",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a3b94d62-efa4-479a-9215-e094b5a73061",
    "outputId": "12cbd8a7-dfce-4155-cf1b-4c57c56c4637"
   },
   "outputs": [],
   "source": [
    "# !llamaindex-cli download-llamadataset PatronusAIFinanceBenchDataset --download-dir ./data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d58be293-ced5-4cf4-90e4-11b1c0af5620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rag_dataset.json  source_files\ttest_sample\n"
     ]
    }
   ],
   "source": [
    "!ls ./data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fba575e-2635-4598-a74a-d4036c1816db",
   "metadata": {
    "id": "2fba575e-2635-4598-a74a-d4036c1816db"
   },
   "source": [
    "## 1. Pipeline chargement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iCaePX5DCyJ7",
   "metadata": {
    "id": "iCaePX5DCyJ7"
   },
   "source": [
    "**Il y a 32 pdfs d'une centaine de pages dans les données PatronusAIFinanceBenchDataset .**\n",
    "\n",
    "Définition du Reader :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9K7iToMEbdc",
   "metadata": {
    "id": "f9K7iToMEbdc"
   },
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "# define our reader with the directory containing the 32 pdf files\n",
    "\n",
    "input_dir = \"./data/source_files\"  # \"./data/source_files\" \"./data/test_sample\"\n",
    "\n",
    "reader = SimpleDirectoryReader(\n",
    "    input_dir=input_dir,  \n",
    "    #required_exts=[\".pdf\"],\n",
    "    recursive=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AwbS0ztWEorx",
   "metadata": {
    "id": "AwbS0ztWEorx"
   },
   "source": [
    "### 1.1 Chargement séquentiel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f49f7e5b-6430-426b-b239-e9280ea7b229",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f49f7e5b-6430-426b-b239-e9280ea7b229",
    "outputId": "982ad887-3e78-4fd9-f8b5-686221db1052"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading files:  94%|█████████████████████████████████████████████████████████████▉    | 30/32 [13:02<00:24, 12.12s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7ff6bc424a70 state=finished raised DependencyError>]. Skipping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading files: 100%|██████████████████████████████████████████████████████████████████| 32/32 [13:23<00:00, 25.12s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Création de 4207 documents en 804.0599935054779s.\n",
      "Wed Feb 12 08:31:02 2025    ./profiling/stats_sequential_load\n",
      "\n",
      "         1820747926 function calls (1817826685 primitive calls) in 822.543 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 1324 to 15 due to restriction <15>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "      344    0.222    0.001 1014.681    2.950 nest_asyncio.py:100(_run_once)\n",
      "       32    0.000    0.000  822.504   25.703 base.py:493(load_file)\n",
      "       32    0.000    0.000  821.071   25.658 __init__.py:328(wrapped_f)\n",
      "     4207    2.418    0.001  795.196    0.189 _page.py:2266(extract_text)\n",
      "4345/4207   12.929    0.003  783.965    0.186 _page.py:1822(_extract_text)\n",
      "       32    0.000    0.000  728.161   22.755 __init__.py:465(__call__)\n",
      "       34    0.055    0.002  579.357   17.040 base.py:36(load_data)\n",
      "     4345    0.014    0.000  558.427    0.129 _data_structures.py:1418(operations)\n",
      "     4345   80.612    0.019  548.878    0.126 _data_structures.py:1294(_parse_content_stream)\n",
      "35812602/33327563   64.684    0.000  348.212    0.000 _data_structures.py:1446(read_object)\n",
      " 23032437   34.599    0.000  192.100    0.000 _page.py:1908(process_operation)\n",
      " 47858941  100.245    0.000  154.131    0.000 _utils.py:218(read_until_regex)\n",
      " 24915949   23.965    0.000  125.093    0.000 _base.py:566(read_from_stream)\n",
      "  8641959   39.414    0.000   97.993    0.000 _utils.py:14(read_hex_string_from_stream)\n",
      "  9418815   11.495    0.000   79.230    0.000 _page.py:1786(_handle_tj)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x7ff6bcbd40b0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with cProfile.Profile() as profiler:\n",
    "    tic = time.time()\n",
    "    documents = reader.load_data(show_progress=True)\n",
    "    profiler.dump_stats('./profiling/stats_sequential_load')\n",
    "\n",
    "print(f\"\\nCréation de {len(documents)} documents en {time.time()-tic}s.\")\n",
    "p = pstats.Stats(\"./profiling/stats_sequential_load\")\n",
    "p.strip_dirs().sort_stats(SortKey.CUMULATIVE).print_stats(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "K-CJ5cr6hdPM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K-CJ5cr6hdPM",
    "outputId": "18fd25f7-4fe9-40b9-c694-b0241db9e724"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps d'exécution moyen du loader sur 7 ittérations :\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7ff6b100a2d0 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7ff6b25668a0 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7ff6b2fe6ae0 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7ff6b2bcaab0 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7ff6b5bd6a20 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7ff6b49c2f30 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7ff6b5a7cd40 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7ff6b355f6e0 state=finished raised DependencyError>]. Skipping...\n",
      "3min 28s ± 994 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Temps d'exécution moyen du loader sur 7 ittérations :\")\n",
    "%timeit reader.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "n4hRYI8RIYwB",
   "metadata": {
    "id": "n4hRYI8RIYwB"
   },
   "source": [
    "### 1.2 Chargement parallèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "vjYOfR3_RDB7",
   "metadata": {
    "id": "vjYOfR3_RDB7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPUs: 8\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "num_cpus = multiprocessing.cpu_count()\n",
    "print(f\"Number of CPUs: {num_cpus}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3869775f-652a-45f5-8c27-8884399c5e2a",
   "metadata": {},
   "source": [
    "#### a) Num_workers=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "BnEtFe4AIibM",
   "metadata": {
    "id": "BnEtFe4AIibM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7f3724ba8a40 state=finished raised DependencyError>]. Skipping...\n",
      "\n",
      "Création de 4207 documents en 96.4300651550293s.\n",
      "Wed Feb 12 08:59:44 2025    ./profiling/stats_parallel_load_worker4\n",
      "\n",
      "         117933 function calls (117566 primitive calls) in 99.513 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 596 to 15 due to restriction <15>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "       17    0.000    0.000   99.368    5.845 connection.py:246(recv)\n",
      "      2/1    0.000    0.000   99.258   99.258 base.py:664(load_data)\n",
      "       11    0.000    0.000   99.255    9.023 util.py:208(__call__)\n",
      "        1    0.000    0.000   99.254   99.254 pool.py:738(__exit__)\n",
      "        1    0.000    0.000   99.254   99.254 pool.py:654(terminate)\n",
      "        1    0.000    0.000   99.254   99.254 pool.py:680(_terminate_pool)\n",
      "    19/17    0.000    0.000   99.110    5.830 connection.py:429(_recv_bytes)\n",
      "    38/34    0.000    0.000   99.110    2.915 connection.py:390(_recv)\n",
      "        1    0.000    0.000   99.108   99.108 pool.py:671(_help_stuff_finish)\n",
      "       11    0.000    0.000   99.108    9.010 {method 'acquire' of '_multiprocessing.SemLock' objects}\n",
      "      3/1    0.000    0.000   99.107   99.107 threading.py:1016(_bootstrap)\n",
      "      3/1    0.000    0.000   99.107   99.107 threading.py:1056(_bootstrap_inner)\n",
      "      3/1    0.000    0.000   99.106   99.106 ipkernel.py:744(run_closure)\n",
      "      3/1    0.000    0.000   99.106   99.106 threading.py:999(run)\n",
      "        1    0.000    0.000   99.106   99.106 pool.py:573(_handle_results)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x7ff6feebfa10>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with cProfile.Profile() as profiler:\n",
    "    tic = time.time()\n",
    "    documents = reader.load_data(num_workers=4, show_progress=True)\n",
    "    profiler.dump_stats('./profiling/stats_parallel_load_worker4')\n",
    "    \n",
    "print(f\"\\nCréation de {len(documents)} documents en {time.time()-tic}s.\")\n",
    "p = pstats.Stats(\"./profiling/stats_parallel_load_worker4\")\n",
    "p.strip_dirs().sort_stats(SortKey.CUMULATIVE).print_stats(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1Zy1FMZUhsxh",
   "metadata": {
    "id": "1Zy1FMZUhsxh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps d'exécution moyen du loader sur 7 ittérations :\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7f2d894d2150 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7ff4766f3e60 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7fd181ed3e90 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7fc9eca37d10 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7f722ed14200 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7f11200e3440 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7fb172a06420 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7f0140d34140 state=finished raised DependencyError>]. Skipping...\n",
      "1min 41s ± 1.45 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Temps d'exécution moyen du loader sur 7 ittérations :\")\n",
    "%timeit reader.load_data(num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910b0423-60a1-47f1-9d46-091122fea0db",
   "metadata": {},
   "source": [
    "#### b) Num_workers=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "065155de-b43a-4d46-b788-7f2c3882f1d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7f3eeb0d3c50 state=finished raised DependencyError>]. Skipping...\n",
      "\n",
      "Création de 4207 documents en 93.67148470878601s.\n",
      "Wed Feb 12 09:14:20 2025    ./profiling/stats_parallel_load_worker8\n",
      "\n",
      "         419654 function calls (419167 primitive calls) in 96.877 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 503 to 15 due to restriction <15>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "      2/1    0.000    0.000   96.704   96.704 base.py:664(load_data)\n",
      "        1    0.000    0.000   96.700   96.700 pool.py:738(__exit__)\n",
      "        1    0.000    0.000   96.697   96.697 pool.py:654(terminate)\n",
      "       15    0.000    0.000   96.671    6.445 util.py:208(__call__)\n",
      "        1    0.000    0.000   96.671   96.671 pool.py:680(_terminate_pool)\n",
      "        1    0.000    0.000   96.574   96.574 pool.py:671(_help_stuff_finish)\n",
      "       11    0.017    0.002   96.574    8.779 {method 'acquire' of '_multiprocessing.SemLock' objects}\n",
      "       40    0.000    0.000   96.558    2.414 connection.py:202(send)\n",
      "      3/1    0.000    0.000   96.557   96.557 threading.py:1016(_bootstrap)\n",
      "      3/1    0.000    0.000   96.557   96.557 threading.py:1056(_bootstrap_inner)\n",
      "      3/1    0.000    0.000   96.557   96.557 ipkernel.py:744(run_closure)\n",
      "      3/1    0.005    0.002   96.557   96.557 threading.py:999(run)\n",
      "        1    0.000    0.000   96.557   96.557 pool.py:527(_handle_tasks)\n",
      "       78    0.001    0.000   96.556    1.238 {built-in method posix.write}\n",
      "       45    0.000    0.000   96.556    2.146 connection.py:406(_send_bytes)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x7ff6bca22450>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with cProfile.Profile() as profiler:\n",
    "    tic = time.time()\n",
    "    documents = reader.load_data(num_workers=8, show_progress=True)\n",
    "    profiler.dump_stats('./profiling/stats_parallel_load_worker8')\n",
    "\n",
    "print(f\"\\nCréation de {len(documents)} documents en {time.time()-tic}s.\")\n",
    "p = pstats.Stats(\"./profiling/stats_parallel_load_worker8\")\n",
    "p.strip_dirs().sort_stats(SortKey.CUMULATIVE).print_stats(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64afafa6-5170-496e-950d-5ffee5f3623a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps d'exécution moyen du loader sur 7 ittérations :\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7f2ed93b3c80 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7f56f35044d0 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7fa4c80d3a10 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7f3e05703c20 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7fccdf006060 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7fda4d6d8560 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7f2150debbc0 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7f6657b58f50 state=finished raised DependencyError>]. Skipping...\n",
      "1min 37s ± 1.09 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Temps d'exécution moyen du loader sur 7 ittérations :\")\n",
    "%timeit reader.load_data(num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mxFLZcmCLBqI",
   "metadata": {
    "id": "mxFLZcmCLBqI"
   },
   "source": [
    "### 1.3 Chargement asynchrone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8DseaNnbMFsl",
   "metadata": {
    "id": "8DseaNnbMFsl"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/32 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7ff6bd3d3920 state=finished raised DependencyError>]. Skipping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 32/32 [13:19<00:00, 24.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Création de 4207 documents en 799.2840440273285s.\n",
      "Wed Feb 12 09:40:13 2025    ./profiling/stats_async_load\n",
      "\n",
      "         1820605497 function calls (1817687005 primitive calls) in 827.844 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 741 to 15 due to restriction <15>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "  360/177    0.004    0.000  827.690    4.676 events.py:86(_run)\n",
      "       33    0.000    0.000  827.682   25.081 tasks.py:291(__step)\n",
      "       33    0.000    0.000  827.682   25.081 tasks.py:308(__step_run_and_handle_result)\n",
      "       33    0.000    0.000  827.681   25.081 {method 'send' of 'coroutine' objects}\n",
      "       32    0.000    0.000  827.647   25.864 asyncio.py:75(wrap_awaitable)\n",
      "       32    0.000    0.000  827.645   25.864 base.py:594(aload_file)\n",
      "       32    0.000    0.000  827.568   25.861 base.py:38(aload_data)\n",
      "       32    0.000    0.000  827.565   25.861 __init__.py:328(wrapped_f)\n",
      "       32    0.001    0.000  827.564   25.861 __init__.py:465(__call__)\n",
      "     4207    2.449    0.001  815.861    0.194 _page.py:2266(extract_text)\n",
      "4345/4207   13.232    0.003  803.803    0.191 _page.py:1822(_extract_text)\n",
      "       34    0.063    0.002  754.653   22.196 base.py:36(load_data)\n",
      "     4345    0.020    0.000  575.723    0.133 _data_structures.py:1418(operations)\n",
      "     4345   83.320    0.019  562.593    0.129 _data_structures.py:1294(_parse_content_stream)\n",
      "35812602/33327563   65.073    0.000  354.929    0.000 _data_structures.py:1446(read_object)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x7ff6be0bb020>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with cProfile.Profile() as profiler:\n",
    "    tic = time.time()\n",
    "    documents = await reader.aload_data(show_progress=True)\n",
    "    profiler.dump_stats('./profiling/stats_async_load')\n",
    "    \n",
    "print(f\"\\nCréation de {len(documents)} documents en {time.time()-tic}s.\")\n",
    "p = pstats.Stats(\"./profiling/stats_async_load\")\n",
    "p.strip_dirs().sort_stats(SortKey.CUMULATIVE).print_stats(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "IU9dh0GSh-2r",
   "metadata": {
    "id": "IU9dh0GSh-2r"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps d'exécution moyen du loader sur 7 ittérations :\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7ff6b1c0e3f0 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7ff6b2c17ad0 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7ff6b22a7110 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7ff6b3e2f140 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7ff6b48c9c70 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7ff6b2841970 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7ff6b1cdf890 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7ff6b5f62ae0 state=finished raised DependencyError>]. Skipping...\n",
      "3min 29s ± 278 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Temps d'exécution moyen du loader sur 7 ittérations :\")\n",
    "%timeit asyncio.run(reader.aload_data())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "I_29ZH-mLFJX",
   "metadata": {
    "id": "I_29ZH-mLFJX"
   },
   "source": [
    "### 1.4 Chargement asynchrone et parallèle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f95508-8359-47a1-89ff-0f8604ea77c0",
   "metadata": {},
   "source": [
    "#### a) Num_workers=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "AxlcBM3eSuaw",
   "metadata": {
    "id": "AxlcBM3eSuaw"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/32 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7ff6b57f30e0 state=finished raised DependencyError>]. Skipping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 32/32 [13:19<00:00, 24.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Création de 4207 documents en 799.4066798686981s.\n",
      "Wed Feb 12 10:20:31 2025    ./profiling/stats_parallel_async_load_worker4\n",
      "\n",
      "         1820603263 function calls (1817684729 primitive calls) in 825.804 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 701 to 15 due to restriction <15>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "       33    0.000    0.000  825.793   25.024 tasks.py:291(__step)\n",
      "       33    0.000    0.000  825.792   25.024 tasks.py:308(__step_run_and_handle_result)\n",
      "       33    0.000    0.000  825.792   25.024 {method 'send' of 'coroutine' objects}\n",
      "       34    0.001    0.000  825.677   24.285 dispatcher.py:349(async_wrapper)\n",
      "       32    0.000    0.000  825.673   25.802 asyncio.py:75(wrap_awaitable)\n",
      "       32    0.000    0.000  825.669   25.802 async_utils.py:136(worker)\n",
      "       32    0.001    0.000  825.668   25.802 base.py:594(aload_file)\n",
      "       32    0.000    0.000  825.589   25.800 base.py:38(aload_data)\n",
      "       32    0.000    0.000  825.589   25.800 __init__.py:328(wrapped_f)\n",
      "     4207    2.525    0.001  813.550    0.193 _page.py:2266(extract_text)\n",
      "4345/4207   13.131    0.003  801.569    0.191 _page.py:1822(_extract_text)\n",
      "       32    0.001    0.000  776.850   24.277 __init__.py:465(__call__)\n",
      "       34    0.060    0.002  690.822   20.318 base.py:36(load_data)\n",
      "     4345    0.024    0.000  574.859    0.132 _data_structures.py:1418(operations)\n",
      "     4345   84.011    0.019  563.652    0.130 _data_structures.py:1294(_parse_content_stream)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x7ff6b20fbc80>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with cProfile.Profile() as profiler:\n",
    "    tic = time.time()\n",
    "    documents = await reader.aload_data(num_workers=4, show_progress=True)\n",
    "    profiler.dump_stats('./profiling/stats_parallel_async_load_worker4')\n",
    "\n",
    "print(f\"\\nCréation de {len(documents)} documents en {time.time()-tic}s.\")\n",
    "p = pstats.Stats(\"./profiling/stats_parallel_async_load_worker4\")\n",
    "p.strip_dirs().sort_stats(SortKey.CUMULATIVE).print_stats(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "qacR4M7Iit9e",
   "metadata": {
    "id": "qacR4M7Iit9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps d'exécution moyen du loader sur 7 ittérations :\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7ff6aad12630 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7ff6b3c521e0 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7ff6b2e01b20 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7ff6aaaddb50 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7ff6aa9cd8b0 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7ff6b3a69850 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7ff6b01a98b0 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7ff6b53a5580 state=finished raised DependencyError>]. Skipping...\n",
      "3min 27s ± 663 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Temps d'exécution moyen du loader sur 7 ittérations :\")\n",
    "%timeit asyncio.run(reader.aload_data(num_workers=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dcd6d4-302f-41e3-97d0-0d6a963c039f",
   "metadata": {},
   "source": [
    "#### b) Num_workers=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4033b1c5-8405-4d62-9290-6896976d5ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/32 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7ff6bd3b5010 state=finished raised DependencyError>]. Skipping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 32/32 [13:27<00:00, 25.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Création de 4207 documents en 808.0082750320435s.\n",
      "Wed Feb 12 11:01:04 2025    ./profiling/stats_parallel_async_load_worker8\n",
      "\n",
      "         1820603805 function calls (1817685171 primitive calls) in 820.979 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 733 to 15 due to restriction <15>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "       33    0.000    0.000  820.974   24.878 tasks.py:291(__step)\n",
      "       33    0.000    0.000  820.974   24.878 tasks.py:308(__step_run_and_handle_result)\n",
      "       33    0.000    0.000  820.973   24.878 {method 'send' of 'coroutine' objects}\n",
      "       34    0.001    0.000  820.914   24.145 dispatcher.py:349(async_wrapper)\n",
      "       32    0.000    0.000  820.910   25.653 asyncio.py:75(wrap_awaitable)\n",
      "       32    0.000    0.000  820.906   25.653 async_utils.py:136(worker)\n",
      "       32    0.000    0.000  820.906   25.653 base.py:594(aload_file)\n",
      "       32    0.000    0.000  820.817   25.651 base.py:38(aload_data)\n",
      "       32    0.000    0.000  820.817   25.651 __init__.py:328(wrapped_f)\n",
      "       32    0.000    0.000  820.816   25.651 __init__.py:465(__call__)\n",
      "     4207    2.524    0.001  806.193    0.192 _page.py:2266(extract_text)\n",
      "   261/83    0.005    0.000  795.798    9.588 events.py:86(_run)\n",
      "4345/4207   13.199    0.003  795.294    0.189 _page.py:1822(_extract_text)\n",
      "       34    0.064    0.002  738.053   21.707 base.py:36(load_data)\n",
      "     4345    0.015    0.000  566.206    0.130 _data_structures.py:1418(operations)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x7ff6bd653980>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with cProfile.Profile() as profiler:\n",
    "    tic = time.time()\n",
    "    documents = await reader.aload_data(num_workers=8, show_progress=True)\n",
    "    profiler.dump_stats('./profiling/stats_parallel_async_load_worker8')\n",
    "\n",
    "print(f\"\\nCréation de {len(documents)} documents en {time.time()-tic}s.\")\n",
    "p = pstats.Stats(\"./profiling/stats_parallel_async_load_worker8\")\n",
    "p.strip_dirs().sort_stats(SortKey.CUMULATIVE).print_stats(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce10fc90-9106-41c1-99eb-a7af5d0e7428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps d'exécution moyen du loader sur 7 ittérations :\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7ff6aa451fa0 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7ff6b21e6750 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7ff6b472a450 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7ff6b543e420 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7ff6aa58e000 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7ff6b1dd1ac0 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7ff6b2b01820 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file /mnt/d/PROJET/notebooks/notebooks_test/data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7ff6aa9c9580 state=finished raised DependencyError>]. Skipping...\n",
      "3min 22s ± 283 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Temps d'exécution moyen du loader sur 7 ittérations :\")\n",
    "%timeit asyncio.run(reader.aload_data(num_workers=8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d691b121-20cb-4257-b9eb-f756c169e63a",
   "metadata": {},
   "source": [
    "### 1.5 Chargement asynchrone avec plusieurs tâches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "560acdb3-48c5-4bd1-880d-19c0ae66a0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def lister_fichiers(dossier):\n",
    "    return [str(fichier) for fichier in Path(dossier).rglob('*') if fichier.is_file()]\n",
    "\n",
    "fichiers = lister_fichiers(input_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4086eee6-c736-4d5c-8de7-0e250bc3fccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_filenames_into_splits(filenames, num_jobs):\n",
    "    tic = time.time()\n",
    "    filenames_splits = [filenames[i::num_jobs] for i in range(num_jobs)]\n",
    "    print(f\"Séparation de {len(filenames)} fichiers en {num_jobs} listes en {round(time.time()-tic, 2)}s de taille {[len(job) for job in filenames_splits]}\")\n",
    "    return filenames_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3af305-9e73-4f95-9ff0-33bf2ff3c640",
   "metadata": {},
   "source": [
    "#### a) 4 splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "127a7beb-e15b-414c-85ff-ce16bb5eee29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Séparation de 32 fichiers en 4 listes en 0.0s de taille [8, 8, 8, 8]\n"
     ]
    }
   ],
   "source": [
    "filenames_splits = divide_filenames_into_splits(filenames=fichiers, num_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "618e2c0e-ed24-40b0-8b1d-657eee974bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load file data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7ff6bd32a6c0 state=finished raised DependencyError>]. Skipping...\n",
      "\n",
      "Création de 4207 documents en 802.3483023643494s.\n",
      "Wed Feb 12 11:41:32 2025    ./profiling/stats_parallel_async_load_with_4_split_jobs\n",
      "\n",
      "         1820594467 function calls (1817676443 primitive calls) in 802.343 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 586 to 15 due to restriction <15>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "  173/172    0.239    0.001  812.413    4.723 nest_asyncio.py:100(_run_once)\n",
      "   250/82    0.001    0.000  802.342    9.785 events.py:86(_run)\n",
      "   249/82    0.001    0.000  802.342    9.785 {method 'run' of '_contextvars.Context' objects}\n",
      "       41    0.000    0.000  802.342   19.569 tasks.py:291(__step)\n",
      "       41    0.000    0.000  802.342   19.569 tasks.py:308(__step_run_and_handle_result)\n",
      "       41    0.000    0.000  802.340   19.569 {method 'send' of 'coroutine' objects}\n",
      "       32    0.001    0.000  802.333   25.073 base.py:594(aload_file)\n",
      "       32    0.000    0.000  802.251   25.070 base.py:38(aload_data)\n",
      "       32    0.000    0.000  802.251   25.070 __init__.py:328(wrapped_f)\n",
      "       32    0.001    0.000  801.670   25.052 __init__.py:465(__call__)\n",
      "     4207    2.449    0.001  788.814    0.188 _page.py:2266(extract_text)\n",
      "4345/4207   12.850    0.003  776.335    0.185 _page.py:1822(_extract_text)\n",
      "       34    0.062    0.002  771.861   22.702 base.py:36(load_data)\n",
      "     4345    0.014    0.000  558.029    0.128 _data_structures.py:1418(operations)\n",
      "     4345   81.685    0.019  547.453    0.126 _data_structures.py:1294(_parse_content_stream)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x7ff6b1f938f0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs = [SimpleDirectoryReader(input_files=split).aload_data() for split in filenames_splits]\n",
    "\n",
    "with cProfile.Profile() as profiler:\n",
    "    tic = time.time()\n",
    "    results = await asyncio.gather(*jobs)\n",
    "    profiler.dump_stats('./profiling/stats_parallel_async_load_with_4_split_jobs')\n",
    "\n",
    "nodes = []\n",
    "for result in results:\n",
    "  nodes.extend(result)\n",
    "print(f\"\\nCréation de {len(documents)} documents en {time.time()-tic}s.\")\n",
    "\n",
    "p = pstats.Stats(\"./profiling/stats_parallel_async_load_with_4_split_jobs\")\n",
    "p.strip_dirs().sort_stats(SortKey.CUMULATIVE).print_stats(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "022c1979-3176-4bf6-804b-07df5a8d3fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps d'exécution moyen du loader sur 7 ittérations :\n",
      "Failed to load file data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7ff6b2e30e90 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7ff6b56f4f50 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7ff6b5337aa0 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7ff6aabde3c0 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7ff6b2293110 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7ff6b20b1040 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7ff6b300bd10 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7ff6b12e5010 state=finished raised DependencyError>]. Skipping...\n",
      "3min 22s ± 110 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# Define the async function to be timed\n",
    "async def run_pipeline(filenames_splits):\n",
    "    jobs = [SimpleDirectoryReader(input_files=split).aload_data() for split in filenames_splits]\n",
    "    await asyncio.gather(*jobs)\n",
    "\n",
    "print(f\"Temps d'exécution moyen du loader sur 7 ittérations :\")\n",
    "%timeit asyncio.run(run_pipeline(filenames_splits))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af053475-6dc7-42eb-a0df-80eeaf2aa4f6",
   "metadata": {},
   "source": [
    "#### b) 8 splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7b754cca-b1f5-4872-85f1-b28b278496fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Séparation de 32 fichiers en 8 listes en 0.0s de taille [4, 4, 4, 4, 4, 4, 4, 4]\n"
     ]
    }
   ],
   "source": [
    "filenames_splits = divide_filenames_into_splits(filenames=fichiers, num_jobs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9314cbc6-af70-4609-b5d7-4d8789a1d247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load file data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7ff6b4832360 state=finished raised DependencyError>]. Skipping...\n",
      "\n",
      "Création de 4207 documents en 816.000452041626s.\n",
      "Wed Feb 12 12:22:10 2025    ./profiling/stats_parallel_async_load_with_8_split_jobs\n",
      "\n",
      "         1820594130 function calls (1817676055 primitive calls) in 815.985 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 581 to 15 due to restriction <15>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "  176/175    0.187    0.001  824.071    4.709 nest_asyncio.py:100(_run_once)\n",
      "   263/92    0.001    0.000  815.985    8.869 events.py:86(_run)\n",
      "   262/92    0.001    0.000  815.984    8.869 {method 'run' of '_contextvars.Context' objects}\n",
      "       49    0.000    0.000  815.984   16.653 tasks.py:291(__step)\n",
      "       49    0.000    0.000  815.984   16.653 tasks.py:308(__step_run_and_handle_result)\n",
      "       49    0.000    0.000  815.982   16.653 {method 'send' of 'coroutine' objects}\n",
      "       32    0.001    0.000  815.975   25.499 base.py:594(aload_file)\n",
      "       32    0.000    0.000  815.899   25.497 base.py:38(aload_data)\n",
      "       32    0.000    0.000  815.192   25.475 __init__.py:328(wrapped_f)\n",
      "       32    0.000    0.000  815.003   25.469 __init__.py:465(__call__)\n",
      "     4207    2.478    0.001  803.992    0.191 _page.py:2266(extract_text)\n",
      "4345/4207   12.949    0.003  790.631    0.188 _page.py:1822(_extract_text)\n",
      "       34    0.065    0.002  783.678   23.049 base.py:36(load_data)\n",
      "     4345    0.021    0.000  570.567    0.131 _data_structures.py:1418(operations)\n",
      "     4345   85.043    0.020  557.242    0.128 _data_structures.py:1294(_parse_content_stream)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x7ff6be1434a0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs = [SimpleDirectoryReader(input_files=split).aload_data() for split in filenames_splits]\n",
    "\n",
    "with cProfile.Profile() as profiler:\n",
    "    tic = time.time()\n",
    "    results = await asyncio.gather(*jobs)\n",
    "    profiler.dump_stats('./profiling/stats_parallel_async_load_with_8_split_jobs')\n",
    "    \n",
    "nodes = []\n",
    "for result in results:\n",
    "  nodes.extend(result)\n",
    "print(f\"\\nCréation de {len(documents)} documents en {time.time()-tic}s.\")\n",
    "\n",
    "p = pstats.Stats(\"./profiling/stats_parallel_async_load_with_8_split_jobs\")\n",
    "p.strip_dirs().sort_stats(SortKey.CUMULATIVE).print_stats(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b8102fe6-0fa7-4b69-9ff4-031d1791b2a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps d'exécution moyen du loader sur 7 ittérations :\n",
      "Failed to load file data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7ff6b0f30140 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7ff6aaf37e90 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7ff6b22bc4d0 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7ff6b56c3fe0 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7ff6b5e77860 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7ff6b124bb90 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7ff6b5bc38c0 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7ff6aa880da0 state=finished raised DependencyError>]. Skipping...\n",
      "3min 22s ± 110 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# Define the async function to be timed\n",
    "async def run_pipeline(filenames_splits):\n",
    "    jobs = [SimpleDirectoryReader(input_files=split).aload_data() for split in filenames_splits]\n",
    "    await asyncio.gather(*jobs)\n",
    "\n",
    "print(f\"Temps d'exécution moyen du loader sur 7 ittérations :\")\n",
    "%timeit asyncio.run((run_pipeline(filenames_splits)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8812ac59-a301-4d4f-8ef8-9a7d57d8d9ef",
   "metadata": {},
   "source": [
    "#### c) 1 split par fichier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8bb2e5b4-6567-4033-90b7-37ccf685b8a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load file data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7ff6bc2441a0 state=finished raised DependencyError>]. Skipping...\n",
      "\n",
      "Création de 4207 documents en 807.4125363826752s.\n",
      "Wed Feb 12 13:02:42 2025    ./profiling/stats_async_load_with_1job_per_file\n",
      "\n",
      "         1820597012 function calls (1817678976 primitive calls) in 807.401 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 581 to 15 due to restriction <15>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "  175/174    0.157    0.001  882.249    5.070 nest_asyncio.py:100(_run_once)\n",
      "  333/163    0.001    0.000  807.400    4.953 events.py:86(_run)\n",
      "  332/163    0.001    0.000  807.400    4.953 {method 'run' of '_contextvars.Context' objects}\n",
      "       97    0.000    0.000  807.399    8.324 tasks.py:291(__step)\n",
      "       97    0.000    0.000  807.399    8.324 tasks.py:308(__step_run_and_handle_result)\n",
      "       97    0.000    0.000  807.396    8.324 {method 'send' of 'coroutine' objects}\n",
      "       32    0.001    0.000  807.388   25.231 base.py:594(aload_file)\n",
      "       32    0.000    0.000  807.314   25.229 base.py:38(aload_data)\n",
      "       32    0.000    0.000  807.314   25.229 __init__.py:328(wrapped_f)\n",
      "       32    0.001    0.000  807.095   25.222 __init__.py:465(__call__)\n",
      "     4207    2.492    0.001  794.900    0.189 _page.py:2266(extract_text)\n",
      "4345/4207   12.820    0.003  778.205    0.185 _page.py:1822(_extract_text)\n",
      "       34    0.057    0.002  680.883   20.026 base.py:36(load_data)\n",
      "     4345    0.034    0.000  561.923    0.129 _data_structures.py:1418(operations)\n",
      "     4345   85.008    0.020  550.750    0.127 _data_structures.py:1294(_parse_content_stream)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x7ff6bd6a4140>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs = [SimpleDirectoryReader(input_files=[file]).aload_data() for file in fichiers]\n",
    "\n",
    "with cProfile.Profile() as profiler:\n",
    "    tic = time.time()\n",
    "    results = await asyncio.gather(*jobs)\n",
    "    profiler.dump_stats('./profiling/stats_async_load_with_1job_per_file')\n",
    "    \n",
    "nodes = []\n",
    "for result in results:\n",
    "  nodes.extend(result)\n",
    "print(f\"\\nCréation de {len(documents)} documents en {time.time()-tic}s.\")\n",
    "\n",
    "p = pstats.Stats(\"./profiling/stats_async_load_with_1job_per_file\")\n",
    "p.strip_dirs().sort_stats(SortKey.CUMULATIVE).print_stats(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cd5683aa-60d1-42f7-bfeb-a6fa703ead26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps d'exécution moyen du loader sur 7 ittérations :\n",
      "Failed to load file data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7ff6b2497020 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7ff6b2fc3b30 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7ff6b50375f0 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7ff6b12676e0 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7ff6b5b56d80 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7ff6b17f6ab0 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7ff6b6446c60 state=finished raised DependencyError>]. Skipping...\n",
      "Failed to load file data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7ff6aa666e40 state=finished raised DependencyError>]. Skipping...\n",
      "3min 22s ± 272 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# Define the async function to be timed\n",
    "async def run_pipeline(fichiers):\n",
    "    jobs = [SimpleDirectoryReader(input_files=[file]).aload_data() for file in fichiers]\n",
    "    await asyncio.gather(*jobs)\n",
    "\n",
    "print(f\"Temps d'exécution moyen du loader sur 7 ittérations :\")\n",
    "%timeit asyncio.run((run_pipeline(fichiers)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323a4d56-79bb-4c3b-a902-ee7f45e6fde2",
   "metadata": {},
   "source": [
    "### 1.6 Parallèle sans utiliser num_workers de llamaindex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c776ef-d377-4e37-8d5a-f4a3c6d74d6b",
   "metadata": {},
   "source": [
    "#### 8 processus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bfe69824-d19c-42e2-83df-4eac4b02ab03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Séparation de 32 fichiers en 8 listes en 0.0s de taille [4, 4, 4, 4, 4, 4, 4, 4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading files: 100%|████████████████████████████████████████████████████████████████████| 4/4 [01:35<00:00, 23.81s/file]\n",
      "Loading files: 100%|████████████████████████████████████████████████████████████████████| 4/4 [02:03<00:00, 30.89s/file]\n",
      "Loading files:  75%|███████████████████████████████████████████████████                 | 3/4 [02:20<00:47, 47.71s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load file data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7ff6b6f16c00 state=finished raised DependencyError>]. Skipping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading files: 100%|████████████████████████████████████████████████████████████████████| 4/4 [02:20<00:00, 35.08s/file]\n",
      "Loading files: 100%|████████████████████████████████████████████████████████████████████| 4/4 [02:58<00:00, 44.55s/file]\n",
      "Loading files: 100%|████████████████████████████████████████████████████████████████████| 4/4 [03:03<00:00, 46.00s/file]\n",
      "Loading files: 100%|████████████████████████████████████████████████████████████████████| 4/4 [03:15<00:00, 48.91s/file]\n",
      "Loading files: 100%|████████████████████████████████████████████████████████████████████| 4/4 [03:34<00:00, 53.74s/file]\n",
      "Loading files: 100%|████████████████████████████████████████████████████████████████████| 4/4 [03:57<00:00, 59.45s/file]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Création de 4207 documents en 238.05858945846558s.\n",
      "Wed Feb 12 13:33:42 2025    ./profiling/stats_custom_parallel_load\n",
      "\n",
      "         84873 function calls (83603 primitive calls) in 238.023 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 480 to 15 due to restriction <15>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "  201/200    0.000    0.000  238.019    1.190 threading.py:1153(_wait_for_tstate_lock)\n",
      "        1    0.000    0.000  238.018  238.018 _base.py:646(__exit__)\n",
      "        1    0.000    0.000  238.018  238.018 process.py:864(shutdown)\n",
      "      2/1    0.000    0.000  238.018  238.018 threading.py:1115(join)\n",
      "      2/1    0.000    0.000  237.914  237.914 threading.py:1016(_bootstrap)\n",
      "      2/1    0.000    0.000  237.913  237.913 threading.py:1056(_bootstrap_inner)\n",
      "        1    0.000    0.000  237.913  237.913 process.py:340(run)\n",
      "        1    0.000    0.000  237.913  237.913 process.py:574(join_executor_internals)\n",
      "        1    0.000    0.000  237.913  237.913 process.py:578(_join_executor_internals)\n",
      "       10    0.000    0.000  237.876   23.788 util.py:208(__call__)\n",
      "        1    0.000    0.000  237.876  237.876 queues.py:147(join_thread)\n",
      "        1    0.000    0.000  237.876  237.876 queues.py:214(_finalize_join)\n",
      "        9    0.000    0.000  237.875   26.431 process.py:636(_chain_from_iterable_of_lists)\n",
      "        9    0.000    0.000  237.779   26.420 _base.py:612(result_iterator)\n",
      "       10    0.001    0.000  237.779   23.778 process.py:415(wait_result_broken_or_wakeup)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x7ff6b13556a0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "# Fonction pour charger un segment de données\n",
    "def load_data_segment(file_split):\n",
    "    # Supposons que reader.load_data peut être appelé avec un segment spécifique\n",
    "    return SimpleDirectoryReader(input_files=file_split).load_data(show_progress=True)\n",
    "\n",
    "file_split = divide_filenames_into_splits(filenames=fichiers, num_jobs=8)\n",
    "\n",
    "with cProfile.Profile() as profiler:\n",
    "    tic = time.time()\n",
    "    # Utiliser un pool de processus pour charger les données en parallèle\n",
    "    with ProcessPoolExecutor() as executor:\n",
    "        res = list(executor.map(load_data_segment, file_split))\n",
    "    profiler.dump_stats('./profiling/stats_custom_parallel_load')\n",
    "documents = [doc for res_proc in res for doc in res_proc]\n",
    "\n",
    "print(f\"\\nCréation de {len(documents)} documents en {time.time()-tic}s.\")\n",
    "p = pstats.Stats(\"./profiling/stats_custom_parallel_load\")\n",
    "p.strip_dirs().sort_stats(SortKey.CUMULATIVE).print_stats(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d27700e0-83bb-4b80-9b86-5c85150fd015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Séparation de 32 fichiers en 8 listes en 0.0s de taille [4, 4, 4, 4, 4, 4, 4, 4]\n",
      "Temps d'exécution moyen du loader sur 7 ittérations :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading files: 100%|████████████████████████████████████████████████████████████████████| 4/4 [00:28<00:00,  7.16s/file]\n",
      "Loading files: 100%|████████████████████████████████████████████████████████████████████| 4/4 [00:37<00:00,  9.33s/file]\n",
      "Loading files:  75%|███████████████████████████████████████████████████                 | 3/4 [00:42<00:14, 14.61s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load file data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7ff6bc8ea510 state=finished raised DependencyError>]. Skipping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading files: 100%|████████████████████████████████████████████████████████████████████| 4/4 [00:42<00:00, 10.72s/file]\n",
      "Loading files: 100%|████████████████████████████████████████████████████████████████████| 4/4 [00:54<00:00, 13.74s/file]\n",
      "Loading files: 100%|████████████████████████████████████████████████████████████████████| 4/4 [00:55<00:00, 13.86s/file]\n",
      "Loading files: 100%|████████████████████████████████████████████████████████████████████| 4/4 [00:57<00:00, 14.40s/file]\n",
      "Loading files: 100%|████████████████████████████████████████████████████████████████████| 4/4 [01:04<00:00, 16.01s/file]\n",
      "Loading files: 100%|████████████████████████████████████████████████████████████████████| 4/4 [01:09<00:00, 17.37s/file]\n",
      "Loading files: 100%|████████████████████████████████████████████████████████████████████| 4/4 [00:29<00:00,  7.35s/file]\n",
      "Loading files: 100%|████████████████████████████████████████████████████████████████████| 4/4 [00:37<00:00,  9.38s/file]\n",
      "Loading files:  75%|███████████████████████████████████████████████████                 | 3/4 [00:42<00:14, 14.56s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load file data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7ff6b11e9f10 state=finished raised DependencyError>]. Skipping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading files: 100%|████████████████████████████████████████████████████████████████████| 4/4 [00:42<00:00, 10.71s/file]\n",
      "Loading files: 100%|████████████████████████████████████████████████████████████████████| 4/4 [00:52<00:00, 13.17s/file]\n",
      "Loading files: 100%|████████████████████████████████████████████████████████████████████| 4/4 [00:53<00:00, 13.48s/file]\n",
      "Loading files: 100%|████████████████████████████████████████████████████████████████████| 4/4 [00:56<00:00, 14.01s/file]\n",
      "Loading files: 100%|████████████████████████████████████████████████████████████████████| 4/4 [01:01<00:00, 15.40s/file]\n",
      "Loading files: 100%|████████████████████████████████████████████████████████████████████| 4/4 [01:06<00:00, 16.74s/file]\n",
      "Loading files: 100%|████████████████████████████████████████████████████████████████████| 4/4 [00:29<00:00,  7.28s/file]\n",
      "Loading files: 100%|████████████████████████████████████████████████████████████████████| 4/4 [00:37<00:00,  9.45s/file]\n",
      "Loading files:  75%|███████████████████████████████████████████████████                 | 3/4 [00:42<00:14, 14.41s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load file data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7ff6b3e2c560 state=finished raised DependencyError>]. Skipping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading files: 100%|████████████████████████████████████████████████████████████████████| 4/4 [00:42<00:00, 10.63s/file]\n",
      "Loading files: 100%|████████████████████████████████████████████████████████████████████| 4/4 [00:52<00:00, 13.23s/file]\n",
      "Loading files: 100%|████████████████████████████████████████████████████████████████████| 4/4 [00:54<00:00, 13.58s/file]\n",
      "Loading files: 100%|████████████████████████████████████████████████████████████████████| 4/4 [00:55<00:00, 13.92s/file]\n",
      "Loading files: 100%|████████████████████████████████████████████████████████████████████| 4/4 [01:01<00:00, 15.48s/file]\n",
      "Loading files: 100%|████████████████████████████████████████████████████████████████████| 4/4 [01:07<00:00, 16.77s/file]\n",
      "Loading files: 100%|████████████████████████████████████████████████████████████████████| 4/4 [00:29<00:00,  7.27s/file]\n",
      "Loading files: 100%|████████████████████████████████████████████████████████████████████| 4/4 [00:37<00:00,  9.39s/file]\n",
      "Loading files:  75%|███████████████████████████████████████████████████                 | 3/4 [00:42<00:14, 14.45s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load file data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7ff6b0edf3e0 state=finished raised DependencyError>]. Skipping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading files: 100%|████████████████████████████████████████████████████████████████████| 4/4 [00:42<00:00, 10.64s/file]\n",
      "Loading files: 100%|████████████████████████████████████████████████████████████████████| 4/4 [00:52<00:00, 13.13s/file]\n",
      "Loading files: 100%|████████████████████████████████████████████████████████████████████| 4/4 [00:54<00:00, 13.57s/file]\n",
      "Loading files: 100%|████████████████████████████████████████████████████████████████████| 4/4 [00:56<00:00, 14.06s/file]\n",
      "Loading files: 100%|████████████████████████████████████████████████████████████████████| 4/4 [01:01<00:00, 15.42s/file]\n",
      "Loading files: 100%|████████████████████████████████████████████████████████████████████| 4/4 [01:06<00:00, 16.74s/file]\n",
      "Loading files: 100%|████████████████████████████████████████████████████████████████████| 4/4 [00:29<00:00,  7.30s/file]\n",
      "Loading files: 100%|████████████████████████████████████████████████████████████████████| 4/4 [00:37<00:00,  9.43s/file]\n",
      "Loading files:  75%|███████████████████████████████████████████████████                 | 3/4 [00:42<00:14, 14.42s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load file data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7ff6b1e63260 state=finished raised DependencyError>]. Skipping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading files: 100%|████████████████████████████████████████████████████████████████████| 4/4 [00:42<00:00, 10.62s/file]\n",
      "Loading files: 100%|████████████████████████████████████████████████████████████████████| 4/4 [00:53<00:00, 13.33s/file]\n",
      "Loading files: 100%|████████████████████████████████████████████████████████████████████| 4/4 [00:54<00:00, 13.56s/file]\n",
      "Loading files: 100%|████████████████████████████████████████████████████████████████████| 4/4 [00:55<00:00, 13.97s/file]\n",
      "Loading files: 100%|████████████████████████████████████████████████████████████████████| 4/4 [01:01<00:00, 15.46s/file]\n",
      "Loading files: 100%|████████████████████████████████████████████████████████████████████| 4/4 [01:07<00:00, 16.81s/file]\n",
      "Loading files: 100%|████████████████████████████████████████████████████████████████████| 4/4 [00:29<00:00,  7.30s/file]\n",
      "Loading files: 100%|████████████████████████████████████████████████████████████████████| 4/4 [00:37<00:00,  9.45s/file]\n",
      "Loading files:  75%|███████████████████████████████████████████████████                 | 3/4 [00:42<00:14, 14.48s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load file data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7ff6b3e2e240 state=finished raised DependencyError>]. Skipping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading files: 100%|████████████████████████████████████████████████████████████████████| 4/4 [00:42<00:00, 10.64s/file]\n",
      "Loading files: 100%|████████████████████████████████████████████████████████████████████| 4/4 [00:52<00:00, 13.20s/file]\n",
      "Loading files: 100%|████████████████████████████████████████████████████████████████████| 4/4 [00:53<00:00, 13.50s/file]\n",
      "Loading files: 100%|████████████████████████████████████████████████████████████████████| 4/4 [00:55<00:00, 13.94s/file]\n",
      "Loading files: 100%|████████████████████████████████████████████████████████████████████| 4/4 [01:01<00:00, 15.34s/file]\n",
      "Loading files: 100%|████████████████████████████████████████████████████████████████████| 4/4 [01:07<00:00, 16.78s/file]\n",
      "Loading files: 100%|████████████████████████████████████████████████████████████████████| 4/4 [00:29<00:00,  7.30s/file]\n",
      "Loading files: 100%|████████████████████████████████████████████████████████████████████| 4/4 [00:37<00:00,  9.39s/file]\n",
      "Loading files:  75%|███████████████████████████████████████████████████                 | 3/4 [00:42<00:14, 14.47s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load file data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7ff6b49a5ca0 state=finished raised DependencyError>]. Skipping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading files: 100%|████████████████████████████████████████████████████████████████████| 4/4 [00:42<00:00, 10.65s/file]\n",
      "Loading files: 100%|████████████████████████████████████████████████████████████████████| 4/4 [00:53<00:00, 13.28s/file]\n",
      "Loading files: 100%|████████████████████████████████████████████████████████████████████| 4/4 [00:54<00:00, 13.52s/file]\n",
      "Loading files: 100%|████████████████████████████████████████████████████████████████████| 4/4 [00:56<00:00, 14.07s/file]\n",
      "Loading files: 100%|████████████████████████████████████████████████████████████████████| 4/4 [01:01<00:00, 15.47s/file]\n",
      "Loading files: 100%|████████████████████████████████████████████████████████████████████| 4/4 [01:07<00:00, 16.79s/file]\n",
      "Loading files: 100%|████████████████████████████████████████████████████████████████████| 4/4 [00:29<00:00,  7.28s/file]\n",
      "Loading files: 100%|████████████████████████████████████████████████████████████████████| 4/4 [00:37<00:00,  9.49s/file]\n",
      "Loading files:  75%|███████████████████████████████████████████████████                 | 3/4 [00:42<00:14, 14.51s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load file data/source_files/8255010981931466649.pdf with error: RetryError[<Future at 0x7ff6aae71d60 state=finished raised DependencyError>]. Skipping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading files: 100%|████████████████████████████████████████████████████████████████████| 4/4 [00:42<00:00, 10.69s/file]\n",
      "Loading files: 100%|████████████████████████████████████████████████████████████████████| 4/4 [00:52<00:00, 13.15s/file]\n",
      "Loading files: 100%|████████████████████████████████████████████████████████████████████| 4/4 [00:54<00:00, 13.56s/file]\n",
      "Loading files: 100%|████████████████████████████████████████████████████████████████████| 4/4 [00:56<00:00, 14.08s/file]\n",
      "Loading files: 100%|████████████████████████████████████████████████████████████████████| 4/4 [01:02<00:00, 15.50s/file]\n",
      "Loading files: 100%|████████████████████████████████████████████████████████████████████| 4/4 [01:07<00:00, 16.86s/file]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1min 7s ± 145 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "# Fonction pour charger un segment de données\n",
    "def load_data_segment(file_split):\n",
    "    # Supposons que reader.load_data peut être appelé avec un segment spécifique\n",
    "    return SimpleDirectoryReader(input_files=file_split).load_data(show_progress=True)\n",
    "\n",
    "file_split = divide_filenames_into_splits(filenames=fichiers, num_jobs=8)\n",
    "\n",
    "def run_pipeline(fichiers):\n",
    "    # Utiliser un pool de processus pour charger les données en parallèle\n",
    "    with ProcessPoolExecutor() as executor:\n",
    "        res = list(executor.map(load_data_segment, file_split))\n",
    "\n",
    "print(f\"Temps d'exécution moyen du loader sur 7 ittérations :\")\n",
    "%timeit run_pipeline(fichiers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "B5kFPMi3l-Kd",
   "metadata": {
    "id": "B5kFPMi3l-Kd"
   },
   "source": [
    "### Conclusion chargement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d8df94-2c10-47ef-9034-8d9155922521",
   "metadata": {},
   "source": [
    "  Méthode       | Num_proc | Temps moyen |\n",
    " |---------------|----------|-------------|\n",
    " | Séquentiel     | 1        | 3min34s ±1s   |\n",
    " | Parallèle     | 4 workers       | 1min41s ±1.4s  |\n",
    " | Parallèle     | 8 workers       | 1min37s ±1s  |\n",
    " | Asynchrone     | 1        | 3min29s ±0.4s   |\n",
    " | Asynchrone/Parallèle     | 4 workers        | 3min27s ±3s  |\n",
    " | Asynchrone/Parallèl     | 8 workers        | 3min22s ± 1s   |\n",
    " | Asynchrone/Jobs multiple     | 4 jobs       | 3min22s ±0.2s  |\n",
    " | Asynchrone/Jobs multiple     | 8 jobs       | 3min22s ±0.1s   |\n",
    " | Asynchrone/Jobs multiple     | 1 job par fichier       | 3min22s ±0.2s |\n",
    " | Parallèle sans num_workers    | 8 process       | 1min7s ±0.1s |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b00be91-22ea-403c-b9c4-cd030b7e6c09",
   "metadata": {
    "id": "5b00be91-22ea-403c-b9c4-cd030b7e6c09"
   },
   "source": [
    "## 2. Pipeline de traitement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VTdmVzilKVdk",
   "metadata": {
    "id": "VTdmVzilKVdk"
   },
   "source": [
    "#### Définition du pipeline d'ingestion :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1089adee-bc8a-457f-8d96-113435923d10",
   "metadata": {
    "id": "1089adee-bc8a-457f-8d96-113435923d10"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed3205b1b98a47529aad48c6ff491b3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1e1095ebd3f48f788268307aa8e0dab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "286172fea5d04837b8645cfca090815c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/94.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a44c16ea489c4a11b4f35abb633b8b6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67ae960af18a4f7da6c97552288b03a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/743 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4a4951549a24035a066d0265b59f167",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/133M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b43f2420a43f409a91409631ee16c05c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aab4ec1b5d3a4df69cb23c437fc48381",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25824763092e4ea084249a64052c4e1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26c5ca7c1bb247fdb2aea8960bdc9ff0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61eb822b791e4ea7b24da4d36093e3be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling%2Fconfig.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.core import Document\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "# create the pipeline with transformations\n",
    "pipeline = IngestionPipeline(\n",
    "    transformations=[\n",
    "        SentenceSplitter(chunk_size=512, chunk_overlap=20),\n",
    "        HuggingFaceEmbedding(\"BAAI/bge-small-en-v1.5\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# since we'll be testing performance, using timeit and cProfile\n",
    "# we're going to disable cache\n",
    "pipeline.disable_cache = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e345d8-0524-4e1b-8d11-88a2a916196e",
   "metadata": {
    "id": "20e345d8-0524-4e1b-8d11-88a2a916196e"
   },
   "source": [
    "### 2.1 Exécution séquentielle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80091185-d7ac-4ff2-aba4-e1ba5546a865",
   "metadata": {
    "id": "80091185-d7ac-4ff2-aba4-e1ba5546a865"
   },
   "source": [
    "By default `num_workers` is set to `None` and this will invoke sequential execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9b31aabf-da4d-4a4a-b92c-2b83a75b296a",
   "metadata": {
    "id": "9b31aabf-da4d-4a4a-b92c-2b83a75b296a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dfa0336e6964fb3bd693d040275d58b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/4207 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eab30684166643d79fd8d997cbc14873",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/8974 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Création de 8974 nodes en 40.60011944770813s.\n",
      "Wed Feb 12 21:13:25 2025    ./profiling/stats_sequential_ingestion\n",
      "\n",
      "         38123766 function calls (36550446 primitive calls) in 202.969 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 848 to 15 due to restriction <15>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "   4212/1    0.078    0.000  202.966  202.966 dispatcher.py:253(wrapper)\n",
      "        1    0.000    0.000  202.966  202.966 pipeline.py:451(run)\n",
      "        1    0.000    0.000  202.966  202.966 pipeline.py:69(run_transformations)\n",
      "     2196    0.029    0.000  198.914    0.091 nest_asyncio.py:100(_run_once)\n",
      "        1    0.038    0.038  193.299  193.299 base.py:305(get_text_embedding_batch)\n",
      "      898    0.002    0.000  192.298    0.214 base.py:308(_get_text_embeddings)\n",
      "      898    0.003    0.000  192.296    0.214 base.py:239(_embed)\n",
      "      898    0.007    0.000  192.293    0.214 __init__.py:328(wrapped_f)\n",
      "      898    0.010    0.000  192.266    0.214 __init__.py:465(__call__)\n",
      "      898    0.028    0.000  187.899    0.209 base.py:191(_embed_with_retry)\n",
      "      898    0.158    0.000  187.802    0.209 SentenceTransformer.py:461(encode)\n",
      "      898  142.329    0.158  142.329    0.158 {method 'cpu' of 'torch._C.TensorBase' objects}\n",
      "      898    0.014    0.000   15.888    0.018 SentenceTransformer.py:683(forward)\n",
      "195764/2694    0.329    0.000   15.864    0.006 module.py:1735(_wrapped_call_impl)\n",
      "195764/2694    0.571    0.000   15.856    0.006 module.py:1743(_call_impl)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x7ff5d5f89850>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with cProfile.Profile() as profiler:\n",
    "    tic = time.time()\n",
    "    nodes = pipeline.run(documents=documents, show_progress=True)\n",
    "    profiler.dump_stats('./profiling/stats_sequential_ingestion')\n",
    "\n",
    "print(f\"\\nCréation de {len(nodes)} nodes en {(time.time()-tic)/5}s.\")\n",
    "p = pstats.Stats(\"./profiling/stats_sequential_ingestion\")\n",
    "p.strip_dirs().sort_stats(SortKey.CUMULATIVE).print_stats(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1ac8b9c1-9129-43e6-9d7d-cd50b3abc953",
   "metadata": {
    "id": "1ac8b9c1-9129-43e6-9d7d-cd50b3abc953"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps d'exécution moyen du pipeline sur 7 ittérations :\n",
      "3min 7s ± 1.5 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Temps d'exécution moyen du pipeline sur 7 ittérations :\")\n",
    "%timeit pipeline.run(documents=documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1937fbaa-0cef-494d-b3e1-a5ff268fd8d2",
   "metadata": {
    "id": "1937fbaa-0cef-494d-b3e1-a5ff268fd8d2"
   },
   "source": [
    "### 2.2 Exécution parallèle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf20d688-5994-4cd7-8f52-079b686328fb",
   "metadata": {
    "id": "cf20d688-5994-4cd7-8f52-079b686328fb"
   },
   "source": [
    "A single run. Setting `num_workers` to a value greater than 1 will invoke parallel execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b5d68e6a-a658-46e8-9b71-d857b1c90d50",
   "metadata": {
    "id": "b5d68e6a-a658-46e8-9b71-d857b1c90d50"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Removing unpickleable private attribute _chunking_tokenizer_fn\n",
      "WARNING:root:Removing unpickleable private attribute _split_fns\n",
      "WARNING:root:Removing unpickleable private attribute _sub_sentence_split_fns\n",
      "WARNING:root:Removing unpickleable private attribute _chunking_tokenizer_fn\n",
      "WARNING:root:Removing unpickleable private attribute _split_fns\n",
      "WARNING:root:Removing unpickleable private attribute _sub_sentence_split_fns\n",
      "WARNING:root:Removing unpickleable private attribute _chunking_tokenizer_fn\n",
      "WARNING:root:Removing unpickleable private attribute _split_fns\n",
      "WARNING:root:Removing unpickleable private attribute _sub_sentence_split_fns\n",
      "WARNING:root:Removing unpickleable private attribute _chunking_tokenizer_fn\n",
      "WARNING:root:Removing unpickleable private attribute _split_fns\n",
      "WARNING:root:Removing unpickleable private attribute _sub_sentence_split_fns\n",
      "WARNING:root:Removing unpickleable private attribute _chunking_tokenizer_fn\n",
      "WARNING:root:Removing unpickleable private attribute _split_fns\n",
      "WARNING:root:Removing unpickleable private attribute _sub_sentence_split_fns\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Création de 8974 nodes en 69.8029604434967s.\n",
      "Wed Feb 12 21:44:10 2025    ./profiling/stats_parallel_ingestion_worker4\n",
      "\n",
      "         639667 function calls (637856 primitive calls) in 349.008 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 667 to 15 due to restriction <15>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        9    0.001    0.000  669.616   74.402 connection.py:202(send)\n",
      "      2/1    0.059    0.030  348.943  348.943 dispatcher.py:253(wrapper)\n",
      "        1    0.000    0.000  348.942  348.942 pipeline.py:451(run)\n",
      "        1    0.000    0.000  348.942  348.942 pool.py:738(__exit__)\n",
      "        1    0.000    0.000  348.942  348.942 pool.py:654(terminate)\n",
      "       14    0.000    0.000  348.934   24.924 connection.py:406(_send_bytes)\n",
      "       19    0.008    0.000  348.933   18.365 connection.py:381(_send)\n",
      "       11    0.000    0.000  348.924   31.720 util.py:208(__call__)\n",
      "        1    0.000    0.000  348.924  348.924 pool.py:680(_terminate_pool)\n",
      "       47    0.199    0.004  348.909    7.424 {built-in method posix.write}\n",
      "       36    0.000    0.000  348.711    9.686 {method 'acquire' of '_multiprocessing.SemLock' objects}\n",
      "        1    0.000    0.000  348.711  348.711 pool.py:671(_help_stuff_finish)\n",
      "      3/1    0.000    0.000  348.711  348.711 threading.py:1016(_bootstrap)\n",
      "      3/1    0.000    0.000  348.711  348.711 threading.py:1056(_bootstrap_inner)\n",
      "      3/1    0.000    0.000  348.711  348.711 ipkernel.py:744(run_closure)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x7ff5a246fdd0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with cProfile.Profile() as profiler:\n",
    "    tic = time.time()\n",
    "    nodes = pipeline.run(documents=documents, num_workers=4, show_progress=True)\n",
    "    profiler.dump_stats('./profiling/stats_parallel_ingestion_worker4')\n",
    "\n",
    "print(f\"\\nCréation de {len(nodes)} nodes en {(time.time()-tic)/5}s.\")\n",
    "p = pstats.Stats(\"./profiling/stats_parallel_ingestion_worker4\")\n",
    "p.strip_dirs().sort_stats(SortKey.CUMULATIVE).print_stats(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8bffaefb-f710-4187-a19f-11d10ebae82b",
   "metadata": {
    "id": "8bffaefb-f710-4187-a19f-11d10ebae82b"
   },
   "outputs": [],
   "source": [
    "# Méthode la moins performante, on la commente pour perdre moins de temps\n",
    "# print(f\"Temps d'exécution moyen du pipeline sur 7 ittérations :\")\n",
    "# %timeit pipeline.run(documents=documents, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b404fef3-ea1c-4b38-a558-c5be27bdd9f7",
   "metadata": {
    "id": "b404fef3-ea1c-4b38-a558-c5be27bdd9f7"
   },
   "source": [
    "### 2.3 Exécution asynchrone sur un processeur"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7b8e77-199c-4afc-870d-91fafc112f8e",
   "metadata": {
    "id": "eb7b8e77-199c-4afc-870d-91fafc112f8e"
   },
   "source": [
    "As with the sync case, `num_workers` is default to `None`, which will then lead to single-batch execution of async tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dca073ac-ed85-4d29-821e-2acf37ea5525",
   "metadata": {
    "id": "dca073ac-ed85-4d29-821e-2acf37ea5525"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "639fe14211934eb4a2d8604ab2999867",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/4207 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings: 100%|██████████████████████████████████████████████████████████| 898/898 [03:56<00:00,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Création de 8974 nodes en 49.346013975143435s.\n",
      "Wed Feb 12 21:48:17 2025    ./profiling/stats_async_ingestion\n",
      "\n",
      "         159672490 function calls (146825357 primitive calls) in 246.740 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 854 to 15 due to restriction <15>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "20981/20921    0.081    0.000  246.888    0.012 events.py:86(_run)\n",
      "13182/8975    0.279    0.000  244.394    0.027 dispatcher.py:253(wrapper)\n",
      "    10771    0.039    0.000  237.273    0.022 tasks.py:291(__step)\n",
      "    10771    0.055    0.000  237.210    0.022 tasks.py:308(__step_run_and_handle_result)\n",
      "    10771    0.025    0.000  237.042    0.022 {method 'send' of 'coroutine' objects}\n",
      "     8974    0.099    0.000  235.990    0.026 base.py:284(_aget_text_embedding)\n",
      "     8974    0.032    0.000  234.635    0.026 base.py:296(_get_text_embedding)\n",
      "     8974    0.022    0.000  234.603    0.026 base.py:239(_embed)\n",
      "     8974    0.066    0.000  234.581    0.026 __init__.py:328(wrapped_f)\n",
      "     8974    0.083    0.000  234.317    0.026 __init__.py:465(__call__)\n",
      "     8974    0.220    0.000  233.383    0.026 base.py:191(_embed_with_retry)\n",
      "     8974    1.134    0.000  232.967    0.026 SentenceTransformer.py:461(encode)\n",
      "     8974    0.142    0.000  111.392    0.012 SentenceTransformer.py:683(forward)\n",
      "1956332/26922    3.411    0.000  111.155    0.004 module.py:1735(_wrapped_call_impl)\n",
      "1956332/26922    5.904    0.000  111.089    0.004 module.py:1743(_call_impl)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x7ff5a907fa40>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with cProfile.Profile() as profiler:\n",
    "    tic = time.time()\n",
    "    nodes = await pipeline.arun(documents=documents, show_progress=True)\n",
    "    profiler.dump_stats('./profiling/stats_async_ingestion')\n",
    "\n",
    "print(f\"\\nCréation de {len(nodes)} nodes en {(time.time()-tic)/5}s.\")\n",
    "p = pstats.Stats(\"./profiling/stats_async_ingestion\")\n",
    "p.strip_dirs().sort_stats(SortKey.CUMULATIVE).print_stats(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bb37efa7-3936-4cf8-a029-fcba95205218",
   "metadata": {
    "id": "bb37efa7-3936-4cf8-a029-fcba95205218"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps d'exécution moyen du pipeline sur 7 ittérations :\n",
      "3min 13s ± 2.07 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Temps d'exécution moyen du pipeline sur 7 ittérations :\")\n",
    "%timeit asyncio.run(pipeline.arun(documents=documents))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f482139e-1d0b-41ac-bff0-0c4a86a3ce62",
   "metadata": {
    "id": "f482139e-1d0b-41ac-bff0-0c4a86a3ce62"
   },
   "source": [
    "### 2.4 Exécution asynchrone sur plusieurs processeurs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1e3ede-1ff4-430c-abfb-270be055ff71",
   "metadata": {
    "id": "4b1e3ede-1ff4-430c-abfb-270be055ff71"
   },
   "source": [
    "Here the `ProcessPoolExecutor` from `concurrent.futures` is used to execute processes asynchronously. The tasks are being processed are blocking, but also performed asynchronously on the individual processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3ce7856e-66ee-44ac-94c6-85082d75d327",
   "metadata": {
    "id": "3ce7856e-66ee-44ac-94c6-85082d75d327"
   },
   "outputs": [],
   "source": [
    "# profiler = cProfile.Profile()\n",
    "\n",
    "# tic = time.time()\n",
    "# profiler.enable()\n",
    "# nodes = await pipeline.arun(documents=documents, num_workers=4, show_progress=True)\n",
    "# profiler.disable()\n",
    "# print(f\"\\nCréation de {len(nodes)} nodes en {(time.time()-tic)/5}s.\")\n",
    "\n",
    "# profiler.dump_stats('./profiling/stats_parallel_async_ingestion_worker4')\n",
    "# p = pstats.Stats(\"./profiling/stats_parallel_async_ingestion_worker4\")\n",
    "# p.strip_dirs().sort_stats(SortKey.CUMULATIVE).print_stats(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47f00aa-d19a-4b1a-92c3-8ddabdbd13ba",
   "metadata": {},
   "source": [
    "...\n",
    "\n",
    "RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method\n",
    "\n",
    "...\n",
    "\n",
    "BrokenProcessPool: A process in the process pool was terminated abruptly while the future was running or pending."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a0a0bf6c-510c-44b3-b9f6-570593321817",
   "metadata": {
    "id": "a0a0bf6c-510c-44b3-b9f6-570593321817"
   },
   "outputs": [],
   "source": [
    "# loop = asyncio.get_event_loop()\n",
    "# print(f\"Temps d'exécution moyen du pipeline sur 7 ittérations :\")\n",
    "# %timeit loop.run_until_complete(pipeline.arun(documents=documents, num_workers=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5057e4b-e79d-46a7-90cf-1035b54c69fb",
   "metadata": {},
   "source": [
    "### 2.5 Exécution asynchrone avec des documents par lots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fe92be8f-3b72-4700-ae3a-09df431b88f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_documents_into_splits(documents, num_jobs):\n",
    "    tic = time.time()\n",
    "    documents_splits = [documents[i::num_jobs] for i in range(num_jobs)]\n",
    "    print(f\"Séparation de {len(documents)} documents en {num_jobs} listes en {round(time.time()-tic, 2)}s de taille {[len(job) for job in documents_splits]}\")\n",
    "    return documents_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9ca59a-0cd1-44c0-9294-0446bc9aa267",
   "metadata": {},
   "source": [
    "#### a) 4 splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cd168e82-10d6-4f20-a65f-4e9889f3c0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Séparation de 4207 documents en 4 listes en 0.0s de taille [1052, 1052, 1052, 1051]\n"
     ]
    }
   ],
   "source": [
    "documents_splits = divide_documents_into_splits(documents=documents, num_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b6b2d7ec-ee83-4dc6-b7a8-f41274f8e5c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "605beee8f3f340348b6a47de418488f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/1052 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|                                                                    | 0/223 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9c215ccf3394dd185c683ea7e32cecd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/1052 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aerating embeddings:   0%|                                                                    | 0/226 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c30804948f54e3ebfdb63c07a13f691",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/1052 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[A\u001b[Ating embeddings:   0%|                                                                    | 0/226 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c3c465113654ae6a5fe789aa3df96bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/1051 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Generating embeddings: 100%|██████████████████████████████████████████████████████████| 223/223 [03:52<00:00,  1.04s/it]\n",
      "\n",
      "Generating embeddings: 100%|██████████████████████████████████████████████████████████| 226/226 [03:50<00:00,  1.02s/it]\n",
      "\n",
      "\n",
      "Generating embeddings: 100%|██████████████████████████████████████████████████████████| 226/226 [03:47<00:00,  1.01s/it]\n",
      "\n",
      "\n",
      "\n",
      "Generating embeddings: 100%|██████████████████████████████████████████████████████████| 224/224 [03:45<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Création de 8974 nodes en 46.962664699554445s.\n",
      "Wed Feb 12 22:18:06 2025    ./profiling/stats_parallel_async_ingestion_with_4_split_jobs\n",
      "\n",
      "         159827767 function calls (146994407 primitive calls) in 234.726 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 846 to 15 due to restriction <15>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "  475/473    0.045    0.000  236.054    0.499 nest_asyncio.py:100(_run_once)\n",
      "21141/20622    0.032    0.000  234.667    0.011 events.py:86(_run)\n",
      "21141/20622    0.017    0.000  234.646    0.011 {method 'run' of '_contextvars.Context' objects}\n",
      "    10781    0.036    0.000  234.630    0.022 tasks.py:291(__step)\n",
      "    10781    0.049    0.000  234.571    0.022 tasks.py:308(__step_run_and_handle_result)\n",
      "    10781    0.021    0.000  234.411    0.022 {method 'send' of 'coroutine' objects}\n",
      "13185/8978    0.239    0.000  232.407    0.026 dispatcher.py:253(wrapper)\n",
      "     8974    0.088    0.000  224.776    0.025 base.py:284(_aget_text_embedding)\n",
      "     8974    0.024    0.000  223.577    0.025 base.py:296(_get_text_embedding)\n",
      "     8974    0.017    0.000  223.553    0.025 base.py:239(_embed)\n",
      "     8974    0.056    0.000  223.536    0.025 __init__.py:328(wrapped_f)\n",
      "     8974    0.075    0.000  223.276    0.025 __init__.py:465(__call__)\n",
      "     8974    0.191    0.000  222.325    0.025 base.py:191(_embed_with_retry)\n",
      "     8974    0.926    0.000  221.926    0.025 SentenceTransformer.py:461(encode)\n",
      "     8974    0.126    0.000   99.706    0.011 SentenceTransformer.py:683(forward)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x7ff5d584c680>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs = [pipeline.arun(documents=split, show_progress=True) for split in documents_splits]\n",
    "\n",
    "with cProfile.Profile() as profiler:\n",
    "    tic = time.time()\n",
    "    results = await asyncio.gather(*jobs)\n",
    "    profiler.dump_stats('./profiling/stats_parallel_async_ingestion_with_4_split_jobs')\n",
    "\n",
    "nodes = []\n",
    "for result in results:\n",
    "  nodes.extend(result)\n",
    "print(f\"\\nCréation de {len(nodes)} nodes en {(time.time()-tic)/5}s.\")\n",
    "\n",
    "p = pstats.Stats(\"./profiling/stats_parallel_async_ingestion_with_4_split_jobs\")\n",
    "p.strip_dirs().sort_stats(SortKey.CUMULATIVE).print_stats(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c667e91e-64cf-4d93-b92d-e3cff1b3d0c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps d'exécution moyen du pipeline sur 7 ittérations :\n",
      "3min 11s ± 178 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# Define the async function to be timed\n",
    "async def run_pipeline(documents_splits):\n",
    "    jobs = [pipeline.arun(documents=split) for split in documents_splits]\n",
    "    await asyncio.gather(*jobs)\n",
    "\n",
    "# Use timeit to measure the execution time\n",
    "print(f\"Temps d'exécution moyen du pipeline sur 7 ittérations :\")\n",
    "%timeit asyncio.run(run_pipeline(documents_splits))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ee9304-90c9-4c76-b281-ed2aac9bff8e",
   "metadata": {},
   "source": [
    "#### b) 8 splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a8974cf0-0825-4a83-96d8-81006cd61d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Séparation de 4207 documents en 8 listes en 0.0s de taille [526, 526, 526, 526, 526, 526, 526, 525]\n"
     ]
    }
   ],
   "source": [
    "documents_splits = divide_documents_into_splits(documents=documents, num_jobs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bf7b2d42-56a9-4956-91d3-367da8c779a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Création de 8974 nodes en 46.89188899993896s.\n",
      "Wed Feb 12 22:47:31 2025    ./profiling/stats_parallel_async_ingestion_with_8_split_jobs\n",
      "\n",
      "         159488162 function calls (146664153 primitive calls) in 234.371 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 588 to 15 due to restriction <15>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "20732/20683    0.020    0.000  234.295    0.011 events.py:86(_run)\n",
      "20732/20683    0.017    0.000  234.275    0.011 {method 'run' of '_contextvars.Context' objects}\n",
      "10796/10795    0.038    0.000  234.228    0.022 tasks.py:291(__step)\n",
      "    10795    0.051    0.000  234.167    0.022 tasks.py:308(__step_run_and_handle_result)\n",
      "    10795    0.021    0.000  234.002    0.022 {method 'send' of 'coroutine' objects}\n",
      "13189/8982    0.237    0.000  232.838    0.026 dispatcher.py:253(wrapper)\n",
      "    58/57    0.061    0.001  229.499    4.026 nest_asyncio.py:100(_run_once)\n",
      "     8974    0.089    0.000  225.429    0.025 base.py:284(_aget_text_embedding)\n",
      "     8974    0.025    0.000  224.229    0.025 base.py:296(_get_text_embedding)\n",
      "     8974    0.020    0.000  224.204    0.025 base.py:239(_embed)\n",
      "     8974    0.058    0.000  224.185    0.025 __init__.py:328(wrapped_f)\n",
      "     8974    0.072    0.000  223.921    0.025 __init__.py:465(__call__)\n",
      "     8974    0.196    0.000  222.875    0.025 base.py:191(_embed_with_retry)\n",
      "     8974    0.922    0.000  222.499    0.025 SentenceTransformer.py:461(encode)\n",
      "     8974    0.128    0.000   99.276    0.011 SentenceTransformer.py:683(forward)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x7ff62216d7f0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs = [pipeline.arun(documents=split) for split in documents_splits]\n",
    "\n",
    "with cProfile.Profile() as profiler:\n",
    "    tic = time.time()\n",
    "    results = await asyncio.gather(*jobs)\n",
    "    profiler.dump_stats('./profiling/stats_parallel_async_ingestion_with_8_split_jobs')\n",
    "\n",
    "nodes = []\n",
    "for result in results:\n",
    "  nodes.extend(result)\n",
    "print(f\"\\nCréation de {len(nodes)} nodes en {(time.time()-tic)/5}s.\")\n",
    "\n",
    "p = pstats.Stats(\"./profiling/stats_parallel_async_ingestion_with_8_split_jobs\")\n",
    "p.strip_dirs().sort_stats(SortKey.CUMULATIVE).print_stats(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5eb55432-f60b-4158-9719-b17a3327d8aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps d'exécution moyen du pipeline sur 7 ittérations :\n",
      "3min 11s ± 619 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# Define the async function to be timed\n",
    "async def run_pipeline(documents_splits):\n",
    "    jobs = [pipeline.arun(documents=split) for split in documents_splits]\n",
    "    await asyncio.gather(*jobs)\n",
    "\n",
    "print(f\"Temps d'exécution moyen du pipeline sur 7 ittérations :\")\n",
    "%timeit asyncio.run(run_pipeline(documents_splits))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d2f0fb-dcab-4bdb-ac57-8242db9d3ad7",
   "metadata": {},
   "source": [
    "#### c) 1 document par job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "159f2af1-905f-4c42-8cc7-8d462a0395cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Création de 8974 nodes en 47.553266525268555s.\n",
      "Wed Feb 12 23:17:01 2025    ./profiling/stats_async_ingestion_with_1job_per_doc\n",
      "\n",
      "         162577911 function calls (149689667 primitive calls) in 237.683 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 655 to 15 due to restriction <15>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "43252/43198    0.031    0.000  237.624    0.006 {method 'run' of '_contextvars.Context' objects}\n",
      "    25804    0.063    0.000  237.382    0.009 tasks.py:291(__step)\n",
      "    25804    0.078    0.000  237.287    0.009 tasks.py:308(__step_run_and_handle_result)\n",
      "    25804    0.039    0.000  237.056    0.009 {method 'send' of 'coroutine' objects}\n",
      "        1    0.007    0.007  236.893  236.893 nest_asyncio.py:86(run_until_complete)\n",
      "17388/13181    0.268    0.000  233.636    0.018 dispatcher.py:253(wrapper)\n",
      "     8974    0.090    0.000  225.374    0.025 base.py:284(_aget_text_embedding)\n",
      "     8974    0.026    0.000  224.178    0.025 base.py:296(_get_text_embedding)\n",
      "     8974    0.019    0.000  224.152    0.025 base.py:239(_embed)\n",
      "     8974    0.055    0.000  224.110    0.025 __init__.py:328(wrapped_f)\n",
      "     8974    0.074    0.000  223.874    0.025 __init__.py:465(__call__)\n",
      "     8974    0.195    0.000  222.822    0.025 base.py:191(_embed_with_retry)\n",
      "     8974    0.926    0.000  222.521    0.025 SentenceTransformer.py:461(encode)\n",
      "     8974    0.126    0.000   99.527    0.011 SentenceTransformer.py:683(forward)\n",
      "1956332/26922    3.067    0.000   99.315    0.004 module.py:1735(_wrapped_call_impl)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x7ff6bc49e4e0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "async def process_documents(documents):\n",
    "    jobs = [pipeline.arun(documents=[doc]) for doc in documents]\n",
    "    return await asyncio.gather(*jobs)\n",
    "\n",
    "with cProfile.Profile() as profiler:\n",
    "    tic = time.time()\n",
    "    # Exécuter la fonction asynchrone\n",
    "    results = asyncio.run(process_documents(documents))\n",
    "    profiler.dump_stats('./profiling/stats_async_ingestion_with_1job_per_doc')\n",
    "    \n",
    "nodes = []\n",
    "for result in results:\n",
    "    nodes.extend(result)\n",
    "print(f\"\\nCréation de {len(nodes)} nodes en {(time.time()-tic)/5}s.\")\n",
    "\n",
    "p = pstats.Stats(\"./profiling/stats_async_ingestion_with_1job_per_doc\")\n",
    "p.strip_dirs().sort_stats(SortKey.CUMULATIVE).print_stats(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1b1d2d78-a95b-4d7e-b925-4788ad4f9417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps d'exécution moyen du pipeline sur 7 ittérations :\n",
      "3min 12s ± 354 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# Define the async function to be timed\n",
    "async def run_pipeline(documents):\n",
    "    jobs = [pipeline.arun(documents=[doc]) for doc in documents]\n",
    "    await asyncio.gather(*jobs)\n",
    "\n",
    "print(f\"Temps d'exécution moyen du pipeline sur 7 ittérations :\")\n",
    "%timeit asyncio.run(run_pipeline(documents))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9bfb79-2def-462c-b3bb-d446e3bb9463",
   "metadata": {
    "id": "5c9bfb79-2def-462c-b3bb-d446e3bb9463"
   },
   "source": [
    "### Conclusion Pipeline ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702e90d6-013a-43d6-8c49-dbd78709587a",
   "metadata": {
    "id": "702e90d6-013a-43d6-8c49-dbd78709587a"
   },
   "source": [
    "I'm inclined to remove multi-processing from the ingestion pipeline. It creates more issues than it solves, async is enough (and a lot safer)\n",
    "\n",
    "\n",
    "  Méthode       | Num_proc | Temps moyen |\n",
    " |---------------|----------|-------------|\n",
    " | Séquentiel     | 1        | 3min10s ± 2s   |\n",
    " | Parallèle     | 4 workers       | 5min35s  |\n",
    " | Asynchrone     | 1        | 3min20s ± 1s   |\n",
    " | Asynchrone/Parallèle     | 4 workers        | Error  |\n",
    " | Asynchrone/Jobs multiple     | 4 jobs       | 3min22s  |\n",
    " | Asynchrone/Jobs multiple     | 8 jobs       | 3min19s   |\n",
    " | Asynchrone/Jobs multiple     | 1 job par doc       |  51s  |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbe0f71-8f79-44ab-8dd3-9d6fbe430d1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6c878e-6fa9-4d8a-b466-25688209f3de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c1f678-0bae-484c-9a95-05b168260b80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a25ca51-f033-442f-bf8d-91a690b8634b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "env_llamaindex",
   "language": "python",
   "name": "env_llamaindex"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
